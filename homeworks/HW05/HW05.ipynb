{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 5 - Логистическая регрессия\n",
    "\n",
    "**Задача:** Построить модель для предсказания дефолта по кредиту\n",
    "\n",
    "**Датасет:** S05-hw-dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем нужные библиотеки\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Из sklearn импортируем всё необходимое для работы\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Чтобы графики отображались в ноутбуке\n",
    "%matplotlib inline\n",
    "\n",
    "# Для воспроизводимости результатов\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Загрузка и первичный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем датасет\n",
    "df = pd.read_csv('../../seminars/S05/S05-hw-dataset.csv')\n",
    "\n",
    "# Смотрим первые строки\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Общая информация о данных\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистика по числовым признакам\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем размер датасета\n",
    "print(f\"Количество строк: {df.shape[0]}\")\n",
    "print(f\"Количество столбцов: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим распределение целевой переменной\n",
    "print(\"Распределение таргета (default):\")\n",
    "print(df['default'].value_counts())\n",
    "print(\"\\nВ процентах:\")\n",
    "print(df['default'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы по первичному анализу:\n",
    "\n",
    "- В датасете 3000 наблюдений и 17 столбцов\n",
    "- Все признаки числовые, пропусков нет\n",
    "- Целевая переменная `default` распределена примерно 60% на 40% (класс 0 преобладает, но не критично)\n",
    "- Видимых аномалий в данных нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Подготовка признаков и таргета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем целевую переменную\n",
    "y = df['default']\n",
    "\n",
    "# Выделяем признаки - всё кроме target и client_id\n",
    "X = df.drop(['default', 'client_id'], axis=1)\n",
    "\n",
    "print(f\"Размер X: {X.shape}\")\n",
    "print(f\"Размер y: {y.shape}\")\n",
    "print(f\"\\nПризнаки для обучения:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Разделение на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делим данные на обучающую и тестовую выборки\n",
    "# test_size=0.2 означает что 20% данных идёт на тест\n",
    "# stratify=y - чтобы сохранить пропорции классов в обеих выборках\n",
    "# random_state=42 - для воспроизводимости\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "print(f\"\\nРаспределение классов в train:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nРаспределение классов в test:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Бейзлайн-модель (DummyClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём бейзлайн модель - она просто предсказывает самый частый класс\n",
    "baseline = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "\n",
    "# Обучаем\n",
    "baseline.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания на тесте\n",
    "y_pred_baseline = baseline.predict(X_test)\n",
    "y_pred_proba_baseline = baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Считаем метрики\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "baseline_roc_auc = roc_auc_score(y_test, y_pred_proba_baseline)\n",
    "\n",
    "print(\"Результаты бейзлайн-модели:\")\n",
    "print(f\"Accuracy: {baseline_accuracy:.4f}\")\n",
    "print(f\"ROC-AUC: {baseline_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Комментарий к бейзлайну:\n",
    "\n",
    "Бейзлайн просто предсказывает всегда класс 0 (нет дефолта), потому что он встречается чаще. \n",
    "Это даёт accuracy около 0.6, но ROC-AUC = 0.5 (случайное угадывание). \n",
    "Это минимальная планка качества - любая нормальная модель должна работать лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Логистическая регрессия с подбором параметра C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Будем перебирать разные значения параметра регуляризации C\n",
    "C_values = [0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Перебираем каждое значение C\n",
    "for C in C_values:\n",
    "    # Создаём pipeline с нормализацией и логистической регрессией\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logreg', LogisticRegression(C=C, max_iter=1000, random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Обучаем\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Предсказания\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_pred_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Метрики\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    results.append({\n",
    "        'C': C,\n",
    "        'Accuracy': acc,\n",
    "        'ROC-AUC': roc\n",
    "    })\n",
    "    \n",
    "    print(f\"C={C}: Accuracy={acc:.4f}, ROC-AUC={roc:.4f}\")\n",
    "\n",
    "# Превращаем в таблицу для удобства\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nСводная таблица результатов:\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим лучшее значение C (по ROC-AUC)\n",
    "best_idx = results_df['ROC-AUC'].idxmax()\n",
    "best_C = results_df.loc[best_idx, 'C']\n",
    "print(f\"Лучшее значение C: {best_C}\")\n",
    "print(f\"С метриками: Accuracy={results_df.loc[best_idx, 'Accuracy']:.4f}, ROC-AUC={results_df.loc[best_idx, 'ROC-AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Обучаем финальную модель с лучшим C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём финальную модель с лучшим параметром\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(C=best_C, max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Обучаем\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred_final = final_pipeline.predict(X_test)\n",
    "y_pred_proba_final = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Финальные метрики\n",
    "final_accuracy = accuracy_score(y_test, y_pred_final)\n",
    "final_roc_auc = roc_auc_score(y_test, y_pred_proba_final)\n",
    "\n",
    "print(\"Финальная модель (Логистическая регрессия):\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"ROC-AUC: {final_roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Построение ROC-кривой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаем ROC-кривую\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_final)\n",
    "\n",
    "# Строим график\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Logistic Regression (AUC = {final_roc_auc:.3f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.5)', linewidth=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# Сохраняем график\n",
    "plt.savefig('figures/roc_curve.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"График сохранён в figures/roc_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сводная таблица с результатами обеих моделей\n",
    "comparison = pd.DataFrame({\n",
    "    'Модель': ['Baseline (DummyClassifier)', 'Logistic Regression'],\n",
    "    'Accuracy': [baseline_accuracy, final_accuracy],\n",
    "    'ROC-AUC': [baseline_roc_auc, final_roc_auc]\n",
    "})\n",
    "\n",
    "print(\"Сравнение моделей:\")\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитаем улучшение в процентах\n",
    "accuracy_improvement = ((final_accuracy - baseline_accuracy) / baseline_accuracy) * 100\n",
    "roc_auc_improvement = ((final_roc_auc - baseline_roc_auc) / baseline_roc_auc) * 100\n",
    "\n",
    "print(f\"Улучшение Accuracy: {accuracy_improvement:.2f}%\")\n",
    "print(f\"Улучшение ROC-AUC: {roc_auc_improvement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Выводы\n",
    "\n",
    "### Результаты эксперимента:\n",
    "\n",
    "1. **Бейзлайн-модель** показала accuracy около 0.6 и ROC-AUC = 0.5. Это ожидаемо, так как она просто всегда предсказывает класс 0.\n",
    "\n",
    "2. **Логистическая регрессия** существенно превзошла бейзлайн:\n",
    "   - Accuracy выросла примерно на 20-25%\n",
    "   - ROC-AUC выросла до ~0.75-0.80, что говорит о хорошей способности модели разделять классы\n",
    "\n",
    "3. **Влияние параметра C**: При переборе значений C от 0.01 до 10.0 заметно, что слишком сильная регуляризация (маленькое C) ухудшает качество, а оптимальное значение находится в районе C=1.0 или C=10.0.\n",
    "\n",
    "4. **Общий вывод**: Логистическая регрессия с нормализацией признаков хорошо справляется с задачей предсказания дефолта. Модель стабильно работает и значительно лучше случайного угадывания. Для данной задачи она вполне подходит как базовое решение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
