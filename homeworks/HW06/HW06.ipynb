{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW06: Деревья решений и ансамбли\n",
    "\n",
    "Датасет: S06-hw-dataset-04.csv (бинарная классификация с сильным дисбалансом)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score, roc_curve,\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# фиксируем seed для воспроизводимости\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Загрузка данных и первичный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "      <th>f05</th>\n",
       "      <th>f06</th>\n",
       "      <th>f07</th>\n",
       "      <th>f08</th>\n",
       "      <th>f09</th>\n",
       "      <th>...</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.250210</td>\n",
       "      <td>1.423474</td>\n",
       "      <td>-0.225004</td>\n",
       "      <td>-4.023138</td>\n",
       "      <td>-0.832729</td>\n",
       "      <td>-0.550874</td>\n",
       "      <td>1.772090</td>\n",
       "      <td>2.761690</td>\n",
       "      <td>-0.698750</td>\n",
       "      <td>...</td>\n",
       "      <td>10.938269</td>\n",
       "      <td>0.501178</td>\n",
       "      <td>1.600001</td>\n",
       "      <td>0.314212</td>\n",
       "      <td>1.209735</td>\n",
       "      <td>1.355697</td>\n",
       "      <td>-5.338924</td>\n",
       "      <td>1.153944</td>\n",
       "      <td>-0.153934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.074328</td>\n",
       "      <td>0.376429</td>\n",
       "      <td>0.212831</td>\n",
       "      <td>-0.502074</td>\n",
       "      <td>2.017405</td>\n",
       "      <td>0.625496</td>\n",
       "      <td>1.943785</td>\n",
       "      <td>1.242030</td>\n",
       "      <td>-0.524090</td>\n",
       "      <td>...</td>\n",
       "      <td>7.775262</td>\n",
       "      <td>-4.550195</td>\n",
       "      <td>6.272586</td>\n",
       "      <td>-0.932162</td>\n",
       "      <td>-0.228543</td>\n",
       "      <td>1.735220</td>\n",
       "      <td>-3.827828</td>\n",
       "      <td>0.292165</td>\n",
       "      <td>0.273720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.638481</td>\n",
       "      <td>0.060968</td>\n",
       "      <td>0.746760</td>\n",
       "      <td>2.479653</td>\n",
       "      <td>-0.292858</td>\n",
       "      <td>-0.078139</td>\n",
       "      <td>-2.918423</td>\n",
       "      <td>-0.013186</td>\n",
       "      <td>1.009135</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.448447</td>\n",
       "      <td>-9.593179</td>\n",
       "      <td>-3.093519</td>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.605511</td>\n",
       "      <td>0.829103</td>\n",
       "      <td>-0.085985</td>\n",
       "      <td>2.891408</td>\n",
       "      <td>0.766221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.712916</td>\n",
       "      <td>-1.350969</td>\n",
       "      <td>-0.256473</td>\n",
       "      <td>1.622074</td>\n",
       "      <td>-0.445141</td>\n",
       "      <td>0.911932</td>\n",
       "      <td>-3.440345</td>\n",
       "      <td>1.505192</td>\n",
       "      <td>-1.104348</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.619072</td>\n",
       "      <td>-3.237479</td>\n",
       "      <td>-5.474038</td>\n",
       "      <td>-1.582475</td>\n",
       "      <td>0.198137</td>\n",
       "      <td>3.823409</td>\n",
       "      <td>0.880395</td>\n",
       "      <td>1.148610</td>\n",
       "      <td>0.136732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.905676</td>\n",
       "      <td>-0.206545</td>\n",
       "      <td>-0.068806</td>\n",
       "      <td>4.086026</td>\n",
       "      <td>-1.010045</td>\n",
       "      <td>-0.772644</td>\n",
       "      <td>-4.207688</td>\n",
       "      <td>2.506104</td>\n",
       "      <td>1.589143</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.396844</td>\n",
       "      <td>-10.540129</td>\n",
       "      <td>-5.532811</td>\n",
       "      <td>-1.231203</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>4.298572</td>\n",
       "      <td>-1.558235</td>\n",
       "      <td>0.924673</td>\n",
       "      <td>0.111668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       f01       f02       f03       f04       f05       f06       f07  \\\n",
       "0   1 -1.250210  1.423474 -0.225004 -4.023138 -0.832729 -0.550874  1.772090   \n",
       "1   2  0.074328  0.376429  0.212831 -0.502074  2.017405  0.625496  1.943785   \n",
       "2   3  0.638481  0.060968  0.746760  2.479653 -0.292858 -0.078139 -2.918423   \n",
       "3   4  1.712916 -1.350969 -0.256473  1.622074 -0.445141  0.911932 -3.440345   \n",
       "4   5  0.905676 -0.206545 -0.068806  4.086026 -1.010045 -0.772644 -4.207688   \n",
       "\n",
       "        f08       f09  ...        f52        f53       f54       f55  \\\n",
       "0  2.761690 -0.698750  ...  10.938269   0.501178  1.600001  0.314212   \n",
       "1  1.242030 -0.524090  ...   7.775262  -4.550195  6.272586 -0.932162   \n",
       "2 -0.013186  1.009135  ...  -4.448447  -9.593179 -3.093519  0.029321   \n",
       "3  1.505192 -1.104348  ...  -1.619072  -3.237479 -5.474038 -1.582475   \n",
       "4  2.506104  1.589143  ...  -2.396844 -10.540129 -5.532811 -1.231203   \n",
       "\n",
       "        f56       f57       f58       f59       f60  target  \n",
       "0  1.209735  1.355697 -5.338924  1.153944 -0.153934       0  \n",
       "1 -0.228543  1.735220 -3.827828  0.292165  0.273720       0  \n",
       "2  0.605511  0.829103 -0.085985  2.891408  0.766221       0  \n",
       "3  0.198137  3.823409  0.880395  1.148610  0.136732       0  \n",
       "4  0.000119  4.298572 -1.558235  0.924673  0.111668       0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузка данных\n",
    "df = pd.read_csv('S06-hw-dataset-04.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 62 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      25000 non-null  int64  \n",
      " 1   f01     25000 non-null  float64\n",
      " 2   f02     25000 non-null  float64\n",
      " 3   f03     25000 non-null  float64\n",
      " 4   f04     25000 non-null  float64\n",
      " 5   f05     25000 non-null  float64\n",
      " 6   f06     25000 non-null  float64\n",
      " 7   f07     25000 non-null  float64\n",
      " 8   f08     25000 non-null  float64\n",
      " 9   f09     25000 non-null  float64\n",
      " 10  f10     25000 non-null  float64\n",
      " 11  f11     25000 non-null  float64\n",
      " 12  f12     25000 non-null  float64\n",
      " 13  f13     25000 non-null  float64\n",
      " 14  f14     25000 non-null  float64\n",
      " 15  f15     25000 non-null  float64\n",
      " 16  f16     25000 non-null  float64\n",
      " 17  f17     25000 non-null  float64\n",
      " 18  f18     25000 non-null  float64\n",
      " 19  f19     25000 non-null  float64\n",
      " 20  f20     25000 non-null  float64\n",
      " 21  f21     25000 non-null  float64\n",
      " 22  f22     25000 non-null  float64\n",
      " 23  f23     25000 non-null  float64\n",
      " 24  f24     25000 non-null  float64\n",
      " 25  f25     25000 non-null  float64\n",
      " 26  f26     25000 non-null  float64\n",
      " 27  f27     25000 non-null  float64\n",
      " 28  f28     25000 non-null  float64\n",
      " 29  f29     25000 non-null  float64\n",
      " 30  f30     25000 non-null  float64\n",
      " 31  f31     25000 non-null  float64\n",
      " 32  f32     25000 non-null  float64\n",
      " 33  f33     25000 non-null  float64\n",
      " 34  f34     25000 non-null  float64\n",
      " 35  f35     25000 non-null  float64\n",
      " 36  f36     25000 non-null  float64\n",
      " 37  f37     25000 non-null  float64\n",
      " 38  f38     25000 non-null  float64\n",
      " 39  f39     25000 non-null  float64\n",
      " 40  f40     25000 non-null  float64\n",
      " 41  f41     25000 non-null  float64\n",
      " 42  f42     25000 non-null  float64\n",
      " 43  f43     25000 non-null  float64\n",
      " 44  f44     25000 non-null  float64\n",
      " 45  f45     25000 non-null  float64\n",
      " 46  f46     25000 non-null  float64\n",
      " 47  f47     25000 non-null  float64\n",
      " 48  f48     25000 non-null  float64\n",
      " 49  f49     25000 non-null  float64\n",
      " 50  f50     25000 non-null  float64\n",
      " 51  f51     25000 non-null  float64\n",
      " 52  f52     25000 non-null  float64\n",
      " 53  f53     25000 non-null  float64\n",
      " 54  f54     25000 non-null  float64\n",
      " 55  f55     25000 non-null  float64\n",
      " 56  f56     25000 non-null  float64\n",
      " 57  f57     25000 non-null  float64\n",
      " 58  f58     25000 non-null  float64\n",
      " 59  f59     25000 non-null  float64\n",
      " 60  f60     25000 non-null  float64\n",
      " 61  target  25000 non-null  int64  \n",
      "dtypes: float64(60), int64(2)\n",
      "memory usage: 11.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "      <th>f05</th>\n",
       "      <th>f06</th>\n",
       "      <th>f07</th>\n",
       "      <th>f08</th>\n",
       "      <th>f09</th>\n",
       "      <th>...</th>\n",
       "      <th>f52</th>\n",
       "      <th>f53</th>\n",
       "      <th>f54</th>\n",
       "      <th>f55</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12500.500000</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>-0.004872</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.335329</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.010118</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.957385</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166251</td>\n",
       "      <td>-3.387506</td>\n",
       "      <td>1.749793</td>\n",
       "      <td>-0.013017</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>0.893365</td>\n",
       "      <td>-0.909479</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>-0.000754</td>\n",
       "      <td>0.04920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7217.022701</td>\n",
       "      <td>1.001623</td>\n",
       "      <td>0.995606</td>\n",
       "      <td>1.004367</td>\n",
       "      <td>3.207537</td>\n",
       "      <td>0.993965</td>\n",
       "      <td>1.002172</td>\n",
       "      <td>2.432162</td>\n",
       "      <td>1.830223</td>\n",
       "      <td>1.013470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.234741</td>\n",
       "      <td>4.331576</td>\n",
       "      <td>5.318660</td>\n",
       "      <td>1.001594</td>\n",
       "      <td>0.996409</td>\n",
       "      <td>2.445185</td>\n",
       "      <td>1.962618</td>\n",
       "      <td>0.994320</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>0.21629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.370993</td>\n",
       "      <td>-4.087073</td>\n",
       "      <td>-4.103875</td>\n",
       "      <td>-13.249937</td>\n",
       "      <td>-4.118778</td>\n",
       "      <td>-3.895974</td>\n",
       "      <td>-8.883224</td>\n",
       "      <td>-8.132548</td>\n",
       "      <td>-4.068933</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.021141</td>\n",
       "      <td>-18.332290</td>\n",
       "      <td>-20.336666</td>\n",
       "      <td>-4.349216</td>\n",
       "      <td>-4.119472</td>\n",
       "      <td>-9.508509</td>\n",
       "      <td>-7.919287</td>\n",
       "      <td>-4.038312</td>\n",
       "      <td>-3.812255</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6250.750000</td>\n",
       "      <td>-0.680165</td>\n",
       "      <td>-0.675100</td>\n",
       "      <td>-0.675426</td>\n",
       "      <td>-1.750048</td>\n",
       "      <td>-0.669764</td>\n",
       "      <td>-0.674374</td>\n",
       "      <td>-1.647977</td>\n",
       "      <td>-0.217260</td>\n",
       "      <td>-0.688278</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.897904</td>\n",
       "      <td>-6.278403</td>\n",
       "      <td>-1.775889</td>\n",
       "      <td>-0.689962</td>\n",
       "      <td>-0.676191</td>\n",
       "      <td>-0.735473</td>\n",
       "      <td>-2.226959</td>\n",
       "      <td>-0.666367</td>\n",
       "      <td>-0.665861</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12500.500000</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>0.403483</td>\n",
       "      <td>-0.001309</td>\n",
       "      <td>-0.005994</td>\n",
       "      <td>-0.011349</td>\n",
       "      <td>0.963009</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396946</td>\n",
       "      <td>-3.462072</td>\n",
       "      <td>1.931851</td>\n",
       "      <td>-0.020933</td>\n",
       "      <td>-0.004193</td>\n",
       "      <td>0.888535</td>\n",
       "      <td>-0.923354</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18750.250000</td>\n",
       "      <td>0.679702</td>\n",
       "      <td>0.659523</td>\n",
       "      <td>0.683437</td>\n",
       "      <td>2.486453</td>\n",
       "      <td>0.672299</td>\n",
       "      <td>0.652629</td>\n",
       "      <td>1.658680</td>\n",
       "      <td>2.167758</td>\n",
       "      <td>0.681040</td>\n",
       "      <td>...</td>\n",
       "      <td>2.344956</td>\n",
       "      <td>-0.578540</td>\n",
       "      <td>5.473886</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>0.673722</td>\n",
       "      <td>2.516790</td>\n",
       "      <td>0.395648</td>\n",
       "      <td>0.666474</td>\n",
       "      <td>0.665918</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25000.000000</td>\n",
       "      <td>4.208888</td>\n",
       "      <td>3.984564</td>\n",
       "      <td>3.793442</td>\n",
       "      <td>15.288250</td>\n",
       "      <td>4.020733</td>\n",
       "      <td>4.279607</td>\n",
       "      <td>9.538525</td>\n",
       "      <td>9.321099</td>\n",
       "      <td>4.261349</td>\n",
       "      <td>...</td>\n",
       "      <td>20.717964</td>\n",
       "      <td>18.818764</td>\n",
       "      <td>20.688069</td>\n",
       "      <td>4.338337</td>\n",
       "      <td>3.902131</td>\n",
       "      <td>11.880651</td>\n",
       "      <td>6.778980</td>\n",
       "      <td>3.834922</td>\n",
       "      <td>4.012639</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id           f01           f02           f03           f04  \\\n",
       "count  25000.000000  25000.000000  25000.000000  25000.000000  25000.000000   \n",
       "mean   12500.500000     -0.000386     -0.004872      0.003202      0.335329   \n",
       "std     7217.022701      1.001623      0.995606      1.004367      3.207537   \n",
       "min        1.000000     -4.370993     -4.087073     -4.103875    -13.249937   \n",
       "25%     6250.750000     -0.680165     -0.675100     -0.675426     -1.750048   \n",
       "50%    12500.500000      0.001859     -0.000247      0.013272      0.403483   \n",
       "75%    18750.250000      0.679702      0.659523      0.683437      2.486453   \n",
       "max    25000.000000      4.208888      3.984564      3.793442     15.288250   \n",
       "\n",
       "                f05           f06           f07           f08           f09  \\\n",
       "count  25000.000000  25000.000000  25000.000000  25000.000000  25000.000000   \n",
       "mean      -0.000563     -0.010118      0.001182      0.957385     -0.004658   \n",
       "std        0.993965      1.002172      2.432162      1.830223      1.013470   \n",
       "min       -4.118778     -3.895974     -8.883224     -8.132548     -4.068933   \n",
       "25%       -0.669764     -0.674374     -1.647977     -0.217260     -0.688278   \n",
       "50%       -0.001309     -0.005994     -0.011349      0.963009      0.000414   \n",
       "75%        0.672299      0.652629      1.658680      2.167758      0.681040   \n",
       "max        4.020733      4.279607      9.538525      9.321099      4.261349   \n",
       "\n",
       "       ...           f52           f53           f54           f55  \\\n",
       "count  ...  25000.000000  25000.000000  25000.000000  25000.000000   \n",
       "mean   ...     -0.166251     -3.387506      1.749793     -0.013017   \n",
       "std    ...      4.234741      4.331576      5.318660      1.001594   \n",
       "min    ...    -20.021141    -18.332290    -20.336666     -4.349216   \n",
       "25%    ...     -2.897904     -6.278403     -1.775889     -0.689962   \n",
       "50%    ...     -0.396946     -3.462072      1.931851     -0.020933   \n",
       "75%    ...      2.344956     -0.578540      5.473886      0.661300   \n",
       "max    ...     20.717964     18.818764     20.688069      4.338337   \n",
       "\n",
       "                f56           f57           f58           f59           f60  \\\n",
       "count  25000.000000  25000.000000  25000.000000  25000.000000  25000.000000   \n",
       "mean      -0.001383      0.893365     -0.909479      0.000570     -0.000754   \n",
       "std        0.996409      2.445185      1.962618      0.994320      0.997167   \n",
       "min       -4.119472     -9.508509     -7.919287     -4.038312     -3.812255   \n",
       "25%       -0.676191     -0.735473     -2.226959     -0.666367     -0.665861   \n",
       "50%       -0.004193      0.888535     -0.923354      0.004381      0.002420   \n",
       "75%        0.673722      2.516790      0.395648      0.666474      0.665918   \n",
       "max        3.902131     11.880651      6.778980      3.834922      4.012639   \n",
       "\n",
       "            target  \n",
       "count  25000.00000  \n",
       "mean       0.04920  \n",
       "std        0.21629  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max        1.00000  \n",
       "\n",
       "[8 rows x 62 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета: (25000, 62)\n",
      "Количество пропусков: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Размер датасета: {df.shape}\")\n",
    "print(f\"Количество пропусков: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение таргета:\n",
      "target\n",
      "0    23770\n",
      "1     1230\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Доли классов:\n",
      "target\n",
      "0    0.9508\n",
      "1    0.0492\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# распределение таргета\n",
    "print(\"Распределение таргета:\")\n",
    "print(df['target'].value_counts())\n",
    "print(\"\\nДоли классов:\")\n",
    "print(df['target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет имеет сильный дисбаланс классов, что характерно для задач типа fraud detection. Класс 0 составляет примерно 95-98%, класс 1 - только 2-5%. В такой задаче accuracy не является хорошей метрикой, важнее смотреть на F1 и ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер X: (25000, 60)\n",
      "Размер y: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# выделяем признаки и таргет\n",
    "X = df.drop(['target', 'id'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "print(f\"Размер X: {X.shape}\")\n",
    "print(f\"Размер y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split\n",
    "\n",
    "Разделяем данные с фиксированным random_state для воспроизводимости и stratify=y для сохранения баланса классов в обеих выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (18750, 60)\n",
      "Test: (6250, 60)\n",
      "\n",
      "Распределение классов в train:\n",
      "target\n",
      "0    0.950773\n",
      "1    0.049227\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Распределение классов в test:\n",
      "target\n",
      "0    0.95088\n",
      "1    0.04912\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")\n",
    "print(f\"\\nРаспределение классов в train:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\nРаспределение классов в test:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier:\n",
      "  Accuracy: 0.9509\n",
      "  F1-score: 0.0000\n",
      "  ROC-AUC: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# baseline: предсказывает самый частый класс\n",
    "dummy = DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE)\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "y_pred_proba_dummy = dummy.predict_proba(X_test)[:, 1]\n",
    "\n",
    "dummy_acc = accuracy_score(y_test, y_pred_dummy)\n",
    "dummy_f1 = f1_score(y_test, y_pred_dummy)\n",
    "dummy_roc = roc_auc_score(y_test, y_pred_proba_dummy)\n",
    "\n",
    "print(f\"DummyClassifier:\")\n",
    "print(f\"  Accuracy: {dummy_acc:.4f}\")\n",
    "print(f\"  F1-score: {dummy_f1:.4f}\")\n",
    "print(f\"  ROC-AUC: {dummy_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy показывает высокий accuracy из-за дисбаланса классов, но F1 и ROC-AUC близки к 0 и 0.5 соответственно - это минимум, который должна превзойти любая осмысленная модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры LogReg: {'logreg__C': 0.01}\n",
      "Лучший CV ROC-AUC: 0.8255\n"
     ]
    }
   ],
   "source": [
    "# логистическая регрессия с подбором C\n",
    "logreg_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# подбираем параметр C через CV\n",
    "param_grid_lr = {'logreg__C': [0.01, 0.1, 1.0, 10.0]}\n",
    "grid_lr = GridSearchCV(\n",
    "    logreg_pipe, param_grid_lr, cv=5, scoring='roc_auc', n_jobs=-1\n",
    ")\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры LogReg: {grid_lr.best_params_}\")\n",
    "print(f\"Лучший CV ROC-AUC: {grid_lr.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "  Accuracy: 0.7787\n",
      "  F1-score: 0.2576\n",
      "  ROC-AUC: 0.8423\n"
     ]
    }
   ],
   "source": [
    "# оценка на test\n",
    "y_pred_lr = grid_lr.predict(X_test)\n",
    "y_pred_proba_lr = grid_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "lr_acc = accuracy_score(y_test, y_pred_lr)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr)\n",
    "lr_roc = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "\n",
    "print(f\"LogisticRegression:\")\n",
    "print(f\"  Accuracy: {lr_acc:.4f}\")\n",
    "print(f\"  F1-score: {lr_f1:.4f}\")\n",
    "print(f\"  ROC-AUC: {lr_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия с class_weight='balanced' существенно лучше dummy baseline по F1 и ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Модели недели 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Decision Tree с контролем сложности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры DecisionTree: {'max_depth': 5, 'min_samples_leaf': 20}\n",
      "Лучший CV ROC-AUC: 0.8169\n"
     ]
    }
   ],
   "source": [
    "# дерево решений - подбираем max_depth и min_samples_leaf\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_leaf': [1, 5, 10, 20]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=RANDOM_STATE, class_weight='balanced')\n",
    "grid_dt = GridSearchCV(dt, param_grid_dt, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры DecisionTree: {grid_dt.best_params_}\")\n",
    "print(f\"Лучший CV ROC-AUC: {grid_dt.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree:\n",
      "  Accuracy: 0.8800\n",
      "  F1-score: 0.3708\n",
      "  ROC-AUC: 0.8218\n"
     ]
    }
   ],
   "source": [
    "# оценка на test\n",
    "y_pred_dt = grid_dt.predict(X_test)\n",
    "y_pred_proba_dt = grid_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "dt_acc = accuracy_score(y_test, y_pred_dt)\n",
    "dt_f1 = f1_score(y_test, y_pred_dt)\n",
    "dt_roc = roc_auc_score(y_test, y_pred_proba_dt)\n",
    "\n",
    "print(f\"DecisionTree:\")\n",
    "print(f\"  Accuracy: {dt_acc:.4f}\")\n",
    "print(f\"  F1-score: {dt_f1:.4f}\")\n",
    "print(f\"  ROC-AUC: {dt_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Лучшие параметры RandomForest: {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "Лучший CV ROC-AUC: 0.8910\n"
     ]
    }
   ],
   "source": [
    "# случайный лес - подбираем n_estimators, max_depth, min_samples_leaf\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced', n_jobs=-1)\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры RandomForest: {grid_rf.best_params_}\")\n",
    "print(f\"Лучший CV ROC-AUC: {grid_rf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest:\n",
      "  Accuracy: 0.9722\n",
      "  F1-score: 0.6045\n",
      "  ROC-AUC: 0.8999\n"
     ]
    }
   ],
   "source": [
    "# оценка на test\n",
    "y_pred_rf = grid_rf.predict(X_test)\n",
    "y_pred_proba_rf = grid_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "rf_roc = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "\n",
    "print(f\"RandomForest:\")\n",
    "print(f\"  Accuracy: {rf_acc:.4f}\")\n",
    "print(f\"  F1-score: {rf_f1:.4f}\")\n",
    "print(f\"  ROC-AUC: {rf_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    }
   ],
   "source": [
    "# градиентный бустинг - подбираем learning_rate, n_estimators, max_depth\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "grid_gb = GridSearchCV(gb, param_grid_gb, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры GradientBoosting: {grid_gb.best_params_}\")\n",
    "print(f\"Лучший CV ROC-AUC: {grid_gb.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка на test\n",
    "y_pred_gb = grid_gb.predict(X_test)\n",
    "y_pred_proba_gb = grid_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "gb_acc = accuracy_score(y_test, y_pred_gb)\n",
    "gb_f1 = f1_score(y_test, y_pred_gb)\n",
    "gb_roc = roc_auc_score(y_test, y_pred_proba_gb)\n",
    "\n",
    "print(f\"GradientBoosting:\")\n",
    "print(f\"  Accuracy: {gb_acc:.4f}\")\n",
    "print(f\"  F1-score: {gb_f1:.4f}\")\n",
    "print(f\"  ROC-AUC: {gb_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Stacking Classifier (опционально)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стекинг: комбинируем лучшие модели\n",
    "estimators = [\n",
    "    ('dt', grid_dt.best_estimator_),\n",
    "    ('rf', grid_rf.best_estimator_),\n",
    "    ('gb', grid_gb.best_estimator_)\n",
    "]\n",
    "\n",
    "stacking = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(random_state=RANDOM_STATE),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оценка на test\n",
    "y_pred_stack = stacking.predict(X_test)\n",
    "y_pred_proba_stack = stacking.predict_proba(X_test)[:, 1]\n",
    "\n",
    "stack_acc = accuracy_score(y_test, y_pred_stack)\n",
    "stack_f1 = f1_score(y_test, y_pred_stack)\n",
    "stack_roc = roc_auc_score(y_test, y_pred_proba_stack)\n",
    "\n",
    "print(f\"StackingClassifier:\")\n",
    "print(f\"  Accuracy: {stack_acc:.4f}\")\n",
    "print(f\"  F1-score: {stack_f1:.4f}\")\n",
    "print(f\"  ROC-AUC: {stack_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Сравнение всех моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сводная таблица результатов\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Dummy', 'LogisticRegression', 'DecisionTree', 'RandomForest', 'GradientBoosting', 'Stacking'],\n",
    "    'Accuracy': [dummy_acc, lr_acc, dt_acc, rf_acc, gb_acc, stack_acc],\n",
    "    'F1-score': [dummy_f1, lr_f1, dt_f1, rf_f1, gb_f1, stack_f1],\n",
    "    'ROC-AUC': [dummy_roc, lr_roc, dt_roc, rf_roc, gb_roc, stack_roc]\n",
    "})\n",
    "\n",
    "results_df = results_df.sort_values('ROC-AUC', ascending=False).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем лучшую модель по ROC-AUC\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"Лучшая модель: {best_model_name}\")\n",
    "print(f\"ROC-AUC: {results_df.iloc[0]['ROC-AUC']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. ROC-кривые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-кривые для всех моделей\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "models_roc = [\n",
    "    ('Dummy', y_pred_proba_dummy, dummy_roc),\n",
    "    ('LogisticRegression', y_pred_proba_lr, lr_roc),\n",
    "    ('DecisionTree', y_pred_proba_dt, dt_roc),\n",
    "    ('RandomForest', y_pred_proba_rf, rf_roc),\n",
    "    ('GradientBoosting', y_pred_proba_gb, gb_roc),\n",
    "    ('Stacking', y_pred_proba_stack, stack_roc)\n",
    "]\n",
    "\n",
    "for name, y_proba, auc in models_roc:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={auc:.3f})', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.5)', linewidth=1)\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.title('ROC-кривые всех моделей', fontsize=14)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('artifacts/figures/roc_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Precision-Recall кривая (для дисбаланса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR-кривая для лучших моделей\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for name, y_proba, _ in models_roc[1:]:  # пропускаем Dummy\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    ap = average_precision_score(y_test, y_proba)\n",
    "    plt.plot(recall, precision, label=f'{name} (AP={ap:.3f})', linewidth=2)\n",
    "\n",
    "plt.xlabel('Recall', fontsize=12)\n",
    "plt.ylabel('Precision', fontsize=12)\n",
    "plt.title('Precision-Recall кривые', fontsize=14)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('artifacts/figures/pr_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Confusion Matrix для лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определяем лучшую модель и её предсказания\n",
    "best_models_map = {\n",
    "    'Dummy': (dummy, y_pred_dummy),\n",
    "    'LogisticRegression': (grid_lr, y_pred_lr),\n",
    "    'DecisionTree': (grid_dt, y_pred_dt),\n",
    "    'RandomForest': (grid_rf, y_pred_rf),\n",
    "    'GradientBoosting': (grid_gb, y_pred_gb),\n",
    "    'Stacking': (stacking, y_pred_stack)\n",
    "}\n",
    "\n",
    "best_model, best_y_pred = best_models_map[best_model_name]\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(y_test, best_y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Class 0', 'Class 1'])\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=14)\n",
    "plt.savefig('artifacts/figures/confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4. Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation importance для лучшей модели\n",
    "perm_importance = permutation_importance(\n",
    "    best_model, X_test, y_test, n_repeats=10, random_state=RANDOM_STATE, scoring='roc_auc', n_jobs=-1\n",
    ")\n",
    "\n",
    "# берем топ-15 признаков\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance_mean': perm_importance.importances_mean,\n",
    "    'importance_std': perm_importance.importances_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "top_features = importance_df.head(15)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(top_features)), top_features['importance_mean'], xerr=top_features['importance_std'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Permutation Importance (ROC-AUC)', fontsize=12)\n",
    "plt.title(f'Top-15 важных признаков - {best_model_name}', fontsize=14)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/permutation_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top-15 признаков по важности:\")\n",
    "print(top_features[['feature', 'importance_mean']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Сохранение артефактов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем метрики на test\n",
    "metrics_test = {\n",
    "    'Dummy': {'accuracy': float(dummy_acc), 'f1': float(dummy_f1), 'roc_auc': float(dummy_roc)},\n",
    "    'LogisticRegression': {'accuracy': float(lr_acc), 'f1': float(lr_f1), 'roc_auc': float(lr_roc)},\n",
    "    'DecisionTree': {'accuracy': float(dt_acc), 'f1': float(dt_f1), 'roc_auc': float(dt_roc)},\n",
    "    'RandomForest': {'accuracy': float(rf_acc), 'f1': float(rf_f1), 'roc_auc': float(rf_roc)},\n",
    "    'GradientBoosting': {'accuracy': float(gb_acc), 'f1': float(gb_f1), 'roc_auc': float(gb_roc)},\n",
    "    'Stacking': {'accuracy': float(stack_acc), 'f1': float(stack_f1), 'roc_auc': float(stack_roc)}\n",
    "}\n",
    "\n",
    "with open('artifacts/metrics_test.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics_test, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Метрики сохранены в artifacts/metrics_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для конвертации numpy типов в python типы\n",
    "def convert_to_json_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_json_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, (list, tuple)):\n",
    "        return [convert_to_json_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif obj is None or isinstance(obj, (bool, int, float, str)):\n",
    "        return obj\n",
    "    else:\n",
    "        return str(obj)\n",
    "\n",
    "# сохраняем лучшие параметры и CV-scores\n",
    "search_summaries = {\n",
    "    'LogisticRegression': {\n",
    "        'best_params': convert_to_json_serializable(grid_lr.best_params_),\n",
    "        'best_cv_score': float(grid_lr.best_score_)\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'best_params': convert_to_json_serializable(grid_dt.best_params_),\n",
    "        'best_cv_score': float(grid_dt.best_score_)\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'best_params': convert_to_json_serializable(grid_rf.best_params_),\n",
    "        'best_cv_score': float(grid_rf.best_score_)\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'best_params': convert_to_json_serializable(grid_gb.best_params_),\n",
    "        'best_cv_score': float(grid_gb.best_score_)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('artifacts/search_summaries.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(search_summaries, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Результаты подбора параметров сохранены в artifacts/search_summaries.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем лучшую модель\n",
    "joblib.dump(best_model, 'artifacts/best_model.joblib')\n",
    "print(f\"Лучшая модель ({best_model_name}) сохранена в artifacts/best_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем метаданные лучшей модели\n",
    "best_params = search_summaries.get(best_model_name, {}).get('best_params', 'N/A')\n",
    "\n",
    "best_model_meta = {\n",
    "    'model_name': str(best_model_name),\n",
    "    'best_params': best_params,\n",
    "    'metrics_test': {\n",
    "        'accuracy': float(results_df.iloc[0]['Accuracy']),\n",
    "        'f1': float(results_df.iloc[0]['F1-score']),\n",
    "        'roc_auc': float(results_df.iloc[0]['ROC-AUC'])\n",
    "    },\n",
    "    'dataset': 'S06-hw-dataset-04.csv',\n",
    "    'train_test_split': {'test_size': 0.25, 'random_state': int(RANDOM_STATE), 'stratify': True}\n",
    "}\n",
    "\n",
    "with open('artifacts/best_model_meta.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(best_model_meta, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Метаданные лучшей модели сохранены в artifacts/best_model_meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Выводы\n",
    "\n",
    "1. **Дисбаланс классов**: Датасет имеет сильный дисбаланс (~95-98% класс 0), поэтому accuracy не является информативной метрикой. Для оценки использовали F1-score и ROC-AUC.\n",
    "\n",
    "2. **Базовые модели**: DummyClassifier показал высокий accuracy из-за дисбаланса, но F1≈0 и ROC-AUC=0.5. LogisticRegression с class_weight='balanced' существенно лучше.\n",
    "\n",
    "3. **Деревья решений**: Одиночное дерево склонно к переобучению без контроля сложности. Подбор max_depth и min_samples_leaf критически важен.\n",
    "\n",
    "4. **Ансамбли**: RandomForest и GradientBoosting показали лучшее качество благодаря снижению variance (RF) и bias (GB). Stacking комбинирует сильные стороны разных моделей.\n",
    "\n",
    "5. **Лучшая модель**: Согласно ROC-AUC, лучшей моделью оказалась одна из ансамблевых моделей, что подтверждает их эффективность для сложных задач с дисбалансом.\n",
    "\n",
    "6. **Честный эксперимент**: Фиксированный train/test split, подбор параметров через CV только на train, единые метрики для всех моделей обеспечили корректное сравнение."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
