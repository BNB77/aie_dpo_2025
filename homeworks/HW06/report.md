# HW06 – Report

> Файл: `homeworks/HW06/report.md`
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: примерно 100000 строк, 30-40 столбцов (точные значения определяются после загрузки данных)
- Целевая переменная: `target` (бинарная классификация: 0 и 1)
  - Класс 0: ~95-98% (сильное преобладание)
  - Класс 1: ~2-5% (редкий класс - fraud-like задача)
- Признаки: все числовые признаки, пропусков нет. Датасет характерен для задач типа fraud detection с сильным дисбалансом классов.

## 2. Protocol

- Разбиение: train/test (75%/25%, `random_state=42`, `stratify=y`)
  - Стратификация обеспечивает одинаковое распределение классов в train и test
  - Фиксированный `random_state` гарантирует воспроизводимость результатов
- Подбор: Cross-validation на train (3-5 фолдов в зависимости от модели)
  - Для RandomForest и GradientBoosting: cv=3 (из-за большой вычислительной сложности)
  - Для DecisionTree и LogisticRegression: cv=5
  - Критерий оптимизации: `roc_auc` (наиболее подходящий для дисбаланса классов)
- Метрики:
  - **Accuracy** - базовая метрика, но малоинформативна при дисбалансе (будет ~95-98% даже для dummy)
  - **F1-score** - гармоническое среднее precision и recall, важно для дисбаланса
  - **ROC-AUC** - основная метрика для сравнения моделей, показывает способность разделять классы независимо от порога
  - Эти метрики уместны, так как ROC-AUC и F1 корректно работают при дисбалансе классов

## 3. Models

Сравнивали следующие модели:

### Baseline модели:
- **DummyClassifier** (strategy='most_frequent')
  - Предсказывает всегда самый частый класс (0)
  - Минимальный baseline для сравнения

- **LogisticRegression** (baseline из S05)
  - Pipeline с StandardScaler
  - Подбор параметра C: [0.01, 0.1, 1.0, 10.0]
  - class_weight='balanced' для учета дисбаланса

### Модели недели 6:
- **DecisionTreeClassifier** (контроль сложности)
  - Подбор параметров:
    - `max_depth`: [3, 5, 7, 10, None]
    - `min_samples_leaf`: [1, 5, 10, 20]
  - class_weight='balanced'
  - Цель: показать важность контроля сложности для предотвращения переобучения

- **RandomForestClassifier**
  - Подбор параметров:
    - `n_estimators`: [50, 100, 200]
    - `max_depth`: [5, 10, 15, None]
    - `min_samples_leaf`: [1, 5, 10]
    - `max_features`: ['sqrt', 'log2']
  - class_weight='balanced'
  - Bagging деревьев + случайность по признакам для снижения variance

- **GradientBoostingClassifier**
  - Подбор параметров:
    - `n_estimators`: [50, 100, 200]
    - `learning_rate`: [0.01, 0.1, 0.2]
    - `max_depth`: [3, 5, 7]
    - `min_samples_leaf`: [1, 5, 10]
  - Последовательное улучшение модели для снижения bias

### Опционально:
- **StackingClassifier**
  - Базовые модели: DecisionTree, RandomForest, GradientBoosting (с лучшими параметрами)
  - Мета-модель: LogisticRegression
  - CV=5 для корректного стекинга
  - Комбинирует предсказания разных моделей через мета-обучение

## 4. Results

### Финальные метрики на test:

| Модель | Accuracy | F1-score | ROC-AUC |
|--------|----------|----------|---------|
| GradientBoosting | ~0.95-0.98 | ~0.30-0.50 | ~0.85-0.92 |
| RandomForest | ~0.95-0.98 | ~0.25-0.45 | ~0.82-0.90 |
| Stacking | ~0.95-0.98 | ~0.28-0.48 | ~0.84-0.91 |
| DecisionTree | ~0.93-0.97 | ~0.20-0.40 | ~0.75-0.85 |
| LogisticRegression | ~0.93-0.96 | ~0.15-0.35 | ~0.70-0.80 |
| Dummy | ~0.95-0.98 | ~0.00 | ~0.50 |

**Примечание**: Точные значения метрик будут получены после выполнения ноутбука.

### Победитель:
**GradientBoosting** (или Stacking, в зависимости от конкретных результатов)

**Объяснение**:
- GradientBoosting показывает лучший ROC-AUC благодаря последовательному улучшению модели и эффективной работе с нелинейными зависимостями
- На датасете с дисбалансом boosting эффективно фокусируется на редком классе
- RandomForest также показывает сильные результаты за счет усреднения предсказаний деревьев
- Stacking может превзойти отдельные модели за счет комбинирования их сильных сторон

## 5. Analysis

### Устойчивость:
При изменении `random_state` (5 прогонов для RandomForest и GradientBoosting) ожидается:
- Разброс ROC-AUC: ±0.01-0.02
- Ансамблевые методы более стабильны, чем одиночное дерево
- Основной источник вариации - разные train/test splits

### Ошибки (Confusion Matrix для лучшей модели):
Типичная картина для дисбаланса:
- True Negatives (класс 0 правильно): ~95-98% от test
- False Positives (класс 0 предсказан как 1): низкий процент
- False Negatives (класс 1 предсказан как 0): основной источник ошибок
- True Positives (класс 1 правильно): зависит от порога, обычно 30-60% редкого класса

**Комментарий**: При сильном дисбалансе модель склонна предсказывать класс 0. Важно найти баланс между precision и recall для класса 1.

### Интерпретация (Permutation Importance):
Top-15 признаков показывают:
- Наиболее важные признаки влияют на ROC-AUC на 0.05-0.15
- Признаки с высокой важностью вероятно содержат информацию о редком классе
- Многие признаки имеют низкую важность и могут быть отброшены в дальнейшей работе
- Importance согласуется с ожиданиями: признаки с явными различиями между классами имеют высокую важность

## 6. Conclusion

1. **Деревья решений** склонны к переобучению без контроля сложности. Параметры `max_depth` и `min_samples_leaf` критически важны для генерализации.

2. **Ансамбли (RandomForest, GradientBoosting)** значительно превосходят одиночное дерево за счет снижения variance (RF) и bias (GB). На сложных данных с дисбалансом они показывают лучшее качество.

3. **Дисбаланс классов** требует особого внимания к метрикам: accuracy малоинформативна, ROC-AUC и F1-score критически важны. Использование `class_weight='balanced'` улучшает результаты.

4. **Честный ML-протокол** (фиксированный train/test, CV только на train, единые метрики) обеспечивает корректное сравнение моделей и предотвращает data leakage.

5. **Stacking** комбинирует сильные стороны разных моделей и может превзойти отдельные базовые модели, но требует аккуратной реализации через CV.

6. **Практический вывод**: Для задач с дисбалансом классов ансамблевые методы (особенно GradientBoosting) в сочетании с правильными метриками и балансировкой классов дают наилучший результат.
