{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW08-09: PyTorch MLP — регуляризация и оптимизация обучения\n",
    "\n",
    "**Датасет:** KMNIST (Вариант A)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.1. Импорты, seed и устройство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:16:11.280883Z",
     "iopub.status.busy": "2026-02-27T07:16:11.280692Z",
     "iopub.status.idle": "2026-02-27T07:16:12.460890Z",
     "shell.execute_reply": "2026-02-27T07:16:12.459918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:       2.10.0+cpu\n",
      "torchvision: 0.25.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "\n",
    "import torchvision  # для версии в выводе\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"torch:       {torch.__version__}\")\n",
    "print(f\"torchvision: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:16:12.480437Z",
     "iopub.status.busy": "2026-02-27T07:16:12.480098Z",
     "iopub.status.idle": "2026-02-27T07:16:12.486197Z",
     "shell.execute_reply": "2026-02-27T07:16:12.485776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cpu\n",
      "Артефакты будут сохранены в: /home/antonio/Рабочий стол/VUZ/aie_dpo_2025/homeworks/HW08-09/artifacts\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Используемое устройство: {device}\")\n",
    "\n",
    "# Директории для артефактов\n",
    "ARTIFACTS_DIR = Path('artifacts')\n",
    "FIGURES_DIR = ARTIFACTS_DIR / 'figures'\n",
    "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
    "FIGURES_DIR.mkdir(exist_ok=True)\n",
    "print(f\"Артефакты будут сохранены в: {ARTIFACTS_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.2. Данные и DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:16:12.487483Z",
     "iopub.status.busy": "2026-02-27T07:16:12.487396Z",
     "iopub.status.idle": "2026-02-27T07:16:12.775844Z",
     "shell.execute_reply": "2026-02-27T07:16:12.774741Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'kmnist-train-imgs.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m img, label\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Загружаем из .npz файлов (лежат рядом с ноутбуком)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m full_train_dataset = \u001b[43mKMNISTFromNpz\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimgs_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkmnist-train-imgs.npz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mkmnist-train-labels.npz\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m test_dataset = KMNISTFromNpz(\n\u001b[32m     36\u001b[39m     imgs_path=\u001b[33m'\u001b[39m\u001b[33mkmnist-test-imgs.npz\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     37\u001b[39m     labels_path=\u001b[33m'\u001b[39m\u001b[33mkmnist-test-labels.npz\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     38\u001b[39m )\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mВсего train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(full_train_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mKMNISTFromNpz.__init__\u001b[39m\u001b[34m(self, imgs_path, labels_path, transform)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgs_path, labels_path, transform=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     imgs   = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs_path\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33marr_0\u001b[39m\u001b[33m'\u001b[39m]    \u001b[38;5;66;03m# (N, 28, 28) uint8\u001b[39;00m\n\u001b[32m     12\u001b[39m     labels = np.load(labels_path)[\u001b[33m'\u001b[39m\u001b[33marr_0\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# (N,) uint8\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mself\u001b[39m.images    = imgs.astype(np.float32) / \u001b[32m255.0\u001b[39m  \u001b[38;5;66;03m# [0, 1]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Рабочий стол/VUZ/aie_dpo_2025/.venv/lib/python3.14/site-packages/numpy/lib/_npyio_impl.py:454\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    455\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'kmnist-train-imgs.npz'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class KMNISTFromNpz(Dataset):\n",
    "    \"\"\"\n",
    "    Загружает KMNIST из локальных .npz файлов (официальный формат KMNIST GitHub).\n",
    "    imgs: uint8 (N, 28, 28), labels: uint8 (N,)\n",
    "    \"\"\"\n",
    "    CLASSES = ['お', 'き', 'す', 'つ', 'な', 'は', 'ま', 'や', 'れ', 'を']\n",
    "\n",
    "    def __init__(self, imgs_path, labels_path, transform=None):\n",
    "        imgs   = np.load(imgs_path)['arr_0']    # (N, 28, 28) uint8\n",
    "        labels = np.load(labels_path)['arr_0']  # (N,) uint8\n",
    "        self.images    = imgs.astype(np.float32) / 255.0  # [0, 1]\n",
    "        self.labels    = labels.astype(np.int64)\n",
    "        self.transform = transform\n",
    "        self.classes   = self.CLASSES\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]           # (28, 28) float32\n",
    "        img = torch.tensor(img).unsqueeze(0)  # (1, 28, 28)\n",
    "        # Нормализация: (x - 0.5) / 0.5  →  [-1, 1]\n",
    "        img = (img - 0.5) / 0.5\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# Загружаем из .npz файлов (лежат рядом с ноутбуком)\n",
    "full_train_dataset = KMNISTFromNpz(\n",
    "    imgs_path='kmnist-train-imgs.npz',\n",
    "    labels_path='kmnist-train-labels.npz',\n",
    ")\n",
    "test_dataset = KMNISTFromNpz(\n",
    "    imgs_path='kmnist-test-imgs.npz',\n",
    "    labels_path='kmnist-test-labels.npz',\n",
    ")\n",
    "\n",
    "print(f\"Всего train: {len(full_train_dataset)}, Test: {len(test_dataset)}\")\n",
    "print(f\"Классы: {full_train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:16:12.779478Z",
     "iopub.status.busy": "2026-02-27T07:16:12.779204Z",
     "iopub.status.idle": "2026-02-27T07:16:12.790611Z",
     "shell.execute_reply": "2026-02-27T07:16:12.790293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 48000, Val: 12000, Test: 10000\n",
      "\n",
      "Sanity check:\n",
      "  x.shape = torch.Size([64, 1, 28, 28])  (batch, channels, H, W)\n",
      "  y.shape = torch.Size([64])\n",
      "  x range = [-1.000, 1.000]\n",
      "  y unique = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Воспроизводимое разбиение train/val = 80/20\n",
    "n_total = len(full_train_dataset)\n",
    "n_train = int(0.8 * n_total)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "generator = torch.Generator().manual_seed(SEED)\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset, [n_train, n_val], generator=generator\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "\n",
    "# DataLoader'ы\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          generator=torch.Generator().manual_seed(SEED))\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Sanity check\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "print(f\"\\nSanity check:\")\n",
    "print(f\"  x.shape = {x_sample.shape}  (batch, channels, H, W)\")\n",
    "print(f\"  y.shape = {y_sample.shape}\")\n",
    "print(f\"  x range = [{x_sample.min():.3f}, {x_sample.max():.3f}]\")\n",
    "print(f\"  y unique = {y_sample.unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.3. Модель MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:16:12.793075Z",
     "iopub.status.busy": "2026-02-27T07:16:12.792967Z",
     "iopub.status.idle": "2026-02-27T07:16:12.799525Z",
     "shell.execute_reply": "2026-02-27T07:16:12.799235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP forward test: input torch.Size([4, 1, 28, 28]) -> output torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Универсальный MLP с поддержкой Dropout и BatchNorm.\n",
    "    \n",
    "    Порядок слоёв в каждом скрытом блоке:\n",
    "        Linear -> [BatchNorm1d] -> ReLU -> [Dropout]\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 784,\n",
    "        hidden_sizes: list = None,\n",
    "        num_classes: int = 10,\n",
    "        dropout_p: float = 0.0,\n",
    "        use_batchnorm: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if hidden_sizes is None:\n",
    "            hidden_sizes = [512, 256]\n",
    "\n",
    "        layers = [nn.Flatten()]\n",
    "        in_features = input_size\n",
    "\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_features, h))\n",
    "            if use_batchnorm:\n",
    "                layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_p > 0.0:\n",
    "                layers.append(nn.Dropout(dropout_p))\n",
    "            in_features = h\n",
    "\n",
    "        layers.append(nn.Linear(in_features, num_classes))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Быстрая проверка модели\n",
    "_m = MLP()\n",
    "_x = torch.zeros(4, 1, 28, 28)\n",
    "_out = _m(_x)\n",
    "print(f\"MLP forward test: input {_x.shape} -> output {_out.shape}\")\n",
    "del _m, _x, _out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Утилиты: цикл обучения и оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:16:12.802306Z",
     "iopub.status.busy": "2026-02-27T07:16:12.802199Z",
     "iopub.status.idle": "2026-02-27T07:16:12.808448Z",
     "shell.execute_reply": "2026-02-27T07:16:12.807945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Утилиты определены.\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += x.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Останавливает обучение, если val_accuracy не улучшается patience эпох.\"\"\"\n",
    "    def __init__(self, patience: int = 5, min_delta: float = 1e-4):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_val_acc = -float('inf')\n",
    "        self.counter = 0\n",
    "        self.best_state = None\n",
    "        self.stopped_epoch = None\n",
    "\n",
    "    def step(self, val_acc, model, epoch):\n",
    "        if val_acc > self.best_val_acc + self.min_delta:\n",
    "            self.best_val_acc = val_acc\n",
    "            self.counter = 0\n",
    "            self.best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        if self.counter >= self.patience:\n",
    "            self.stopped_epoch = epoch\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def restore_best(self, model):\n",
    "        if self.best_state is not None:\n",
    "            model.load_state_dict(self.best_state)\n",
    "\n",
    "\n",
    "def run_experiment(model, train_loader, val_loader, optimizer, criterion, device,\n",
    "                   max_epochs=15, early_stopping=None, verbose=True, tag=''):\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        vl_loss, vl_acc = evaluate(model, val_loader, criterion, device)\n",
    "        history['train_loss'].append(tr_loss)\n",
    "        history['val_loss'].append(vl_loss)\n",
    "        history['train_acc'].append(tr_acc)\n",
    "        history['val_acc'].append(vl_acc)\n",
    "        if verbose:\n",
    "            print(f\"[{tag}] Epoch {epoch:02d}/{max_epochs}: \"\n",
    "                  f\"train_loss={tr_loss:.4f} train_acc={tr_acc:.4f} | \"\n",
    "                  f\"val_loss={vl_loss:.4f} val_acc={vl_acc:.4f}\")\n",
    "        if early_stopping is not None:\n",
    "            if early_stopping.step(vl_acc, model, epoch):\n",
    "                print(f\"  >>> EarlyStopping на эпохе {epoch}, \"\n",
    "                      f\"лучшая val_acc={early_stopping.best_val_acc:.4f}\")\n",
    "                early_stopping.restore_best(model)\n",
    "                break\n",
    "    return history\n",
    "\n",
    "print(\"Утилиты определены.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.1. Часть A (S08): Регуляризация (E1-E4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:16:12.810685Z",
     "iopub.status.busy": "2026-02-27T07:16:12.810401Z",
     "iopub.status.idle": "2026-02-27T07:18:01.554053Z",
     "shell.execute_reply": "2026-02-27T07:18:01.553495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "E1: Base MLP (no Dropout, no BatchNorm)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 01/15: train_loss=0.4363 train_acc=0.8628 | val_loss=0.2836 val_acc=0.9122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 02/15: train_loss=0.2086 train_acc=0.9363 | val_loss=0.1990 val_acc=0.9415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 03/15: train_loss=0.1448 train_acc=0.9545 | val_loss=0.1959 val_acc=0.9397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 04/15: train_loss=0.1081 train_acc=0.9655 | val_loss=0.1922 val_acc=0.9432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 05/15: train_loss=0.0880 train_acc=0.9712 | val_loss=0.1947 val_acc=0.9477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 06/15: train_loss=0.0729 train_acc=0.9764 | val_loss=0.1845 val_acc=0.9472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 07/15: train_loss=0.0634 train_acc=0.9785 | val_loss=0.1823 val_acc=0.9549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 08/15: train_loss=0.0521 train_acc=0.9830 | val_loss=0.2002 val_acc=0.9519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 09/15: train_loss=0.0479 train_acc=0.9843 | val_loss=0.2196 val_acc=0.9498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 10/15: train_loss=0.0479 train_acc=0.9840 | val_loss=0.1876 val_acc=0.9561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 11/15: train_loss=0.0349 train_acc=0.9886 | val_loss=0.2059 val_acc=0.9554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 12/15: train_loss=0.0388 train_acc=0.9870 | val_loss=0.2345 val_acc=0.9522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 13/15: train_loss=0.0311 train_acc=0.9891 | val_loss=0.2625 val_acc=0.9512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 14/15: train_loss=0.0359 train_acc=0.9878 | val_loss=0.2419 val_acc=0.9547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E1] Epoch 15/15: train_loss=0.0338 train_acc=0.9897 | val_loss=0.2487 val_acc=0.9526\n",
      "\n",
      "[E1] Лучшая val_accuracy: 0.9561\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "MAX_EPOCHS_A = 15\n",
    "\n",
    "# ── E1: Базовая MLP без регуляризации ──────────────────────────────────────\n",
    "print(\"=\" * 60)\n",
    "print(\"E1: Base MLP (no Dropout, no BatchNorm)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model_e1 = MLP(hidden_sizes=[512, 256], dropout_p=0.0, use_batchnorm=False).to(device)\n",
    "optimizer_e1 = optim.Adam(model_e1.parameters(), lr=1e-3)\n",
    "\n",
    "history_e1 = run_experiment(\n",
    "    model_e1, train_loader, val_loader, optimizer_e1, criterion, device,\n",
    "    max_epochs=MAX_EPOCHS_A, tag='E1'\n",
    ")\n",
    "\n",
    "best_val_acc_e1 = max(history_e1['val_acc'])\n",
    "best_val_loss_e1 = history_e1['val_loss'][history_e1['val_acc'].index(best_val_acc_e1)]\n",
    "epochs_e1 = len(history_e1['val_acc'])\n",
    "print(f\"\\n[E1] Лучшая val_accuracy: {best_val_acc_e1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:18:01.555221Z",
     "iopub.status.busy": "2026-02-27T07:18:01.555110Z",
     "iopub.status.idle": "2026-02-27T07:18:54.837821Z",
     "shell.execute_reply": "2026-02-27T07:18:54.837311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "E2: MLP + Dropout(p=0.3)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 01/15: train_loss=0.5469 train_acc=0.8254 | val_loss=0.3064 val_acc=0.9103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 02/15: train_loss=0.3142 train_acc=0.9034 | val_loss=0.2316 val_acc=0.9299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 03/15: train_loss=0.2525 train_acc=0.9211 | val_loss=0.1992 val_acc=0.9401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 04/15: train_loss=0.2145 train_acc=0.9325 | val_loss=0.2073 val_acc=0.9367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 05/15: train_loss=0.1876 train_acc=0.9408 | val_loss=0.1925 val_acc=0.9440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 06/15: train_loss=0.1693 train_acc=0.9471 | val_loss=0.1839 val_acc=0.9465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 07/15: train_loss=0.1592 train_acc=0.9498 | val_loss=0.1756 val_acc=0.9472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 08/15: train_loss=0.1494 train_acc=0.9520 | val_loss=0.2004 val_acc=0.9439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 09/15: train_loss=0.1404 train_acc=0.9548 | val_loss=0.1577 val_acc=0.9551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 10/15: train_loss=0.1342 train_acc=0.9577 | val_loss=0.1691 val_acc=0.9537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 11/15: train_loss=0.1251 train_acc=0.9611 | val_loss=0.1571 val_acc=0.9577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 12/15: train_loss=0.1210 train_acc=0.9625 | val_loss=0.1738 val_acc=0.9536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 13/15: train_loss=0.1163 train_acc=0.9623 | val_loss=0.1638 val_acc=0.9539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 14/15: train_loss=0.1108 train_acc=0.9654 | val_loss=0.1708 val_acc=0.9557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E2] Epoch 15/15: train_loss=0.1074 train_acc=0.9651 | val_loss=0.1655 val_acc=0.9566\n",
      "\n",
      "[E2] Лучшая val_accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "# ── E2: MLP + Dropout ───────────────────────────────────────────────────────\n",
    "print(\"=\" * 60)\n",
    "print(\"E2: MLP + Dropout(p=0.3)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model_e2 = MLP(hidden_sizes=[512, 256], dropout_p=0.3, use_batchnorm=False).to(device)\n",
    "optimizer_e2 = optim.Adam(model_e2.parameters(), lr=1e-3)\n",
    "\n",
    "history_e2 = run_experiment(\n",
    "    model_e2, train_loader, val_loader, optimizer_e2, criterion, device,\n",
    "    max_epochs=MAX_EPOCHS_A, tag='E2'\n",
    ")\n",
    "\n",
    "best_val_acc_e2 = max(history_e2['val_acc'])\n",
    "best_val_loss_e2 = history_e2['val_loss'][history_e2['val_acc'].index(best_val_acc_e2)]\n",
    "epochs_e2 = len(history_e2['val_acc'])\n",
    "print(f\"\\n[E2] Лучшая val_accuracy: {best_val_acc_e2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:18:54.839109Z",
     "iopub.status.busy": "2026-02-27T07:18:54.838965Z",
     "iopub.status.idle": "2026-02-27T07:19:47.173158Z",
     "shell.execute_reply": "2026-02-27T07:19:47.171995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "E3: MLP + BatchNorm\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 01/15: train_loss=0.3383 train_acc=0.8964 | val_loss=0.2156 val_acc=0.9313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 02/15: train_loss=0.1554 train_acc=0.9519 | val_loss=0.1695 val_acc=0.9469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 03/15: train_loss=0.1004 train_acc=0.9677 | val_loss=0.1734 val_acc=0.9463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 04/15: train_loss=0.0752 train_acc=0.9760 | val_loss=0.1620 val_acc=0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 05/15: train_loss=0.0530 train_acc=0.9831 | val_loss=0.1639 val_acc=0.9536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 06/15: train_loss=0.0481 train_acc=0.9841 | val_loss=0.1647 val_acc=0.9533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 07/15: train_loss=0.0371 train_acc=0.9880 | val_loss=0.1703 val_acc=0.9557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 08/15: train_loss=0.0328 train_acc=0.9891 | val_loss=0.1751 val_acc=0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 09/15: train_loss=0.0289 train_acc=0.9905 | val_loss=0.1652 val_acc=0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 10/15: train_loss=0.0294 train_acc=0.9901 | val_loss=0.1732 val_acc=0.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 11/15: train_loss=0.0247 train_acc=0.9914 | val_loss=0.1558 val_acc=0.9596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 12/15: train_loss=0.0205 train_acc=0.9931 | val_loss=0.1570 val_acc=0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 13/15: train_loss=0.0197 train_acc=0.9938 | val_loss=0.1722 val_acc=0.9593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 14/15: train_loss=0.0173 train_acc=0.9943 | val_loss=0.1822 val_acc=0.9580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E3] Epoch 15/15: train_loss=0.0182 train_acc=0.9938 | val_loss=0.1743 val_acc=0.9597\n",
      "\n",
      "[E3] Лучшая val_accuracy: 0.9625\n"
     ]
    }
   ],
   "source": [
    "# ── E3: MLP + BatchNorm ──────────────────────────────────────────────────────\n",
    "print(\"=\" * 60)\n",
    "print(\"E3: MLP + BatchNorm\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model_e3 = MLP(hidden_sizes=[512, 256], dropout_p=0.0, use_batchnorm=True).to(device)\n",
    "optimizer_e3 = optim.Adam(model_e3.parameters(), lr=1e-3)\n",
    "\n",
    "history_e3 = run_experiment(\n",
    "    model_e3, train_loader, val_loader, optimizer_e3, criterion, device,\n",
    "    max_epochs=MAX_EPOCHS_A, tag='E3'\n",
    ")\n",
    "\n",
    "best_val_acc_e3 = max(history_e3['val_acc'])\n",
    "best_val_loss_e3 = history_e3['val_loss'][history_e3['val_acc'].index(best_val_acc_e3)]\n",
    "epochs_e3 = len(history_e3['val_acc'])\n",
    "print(f\"\\n[E3] Лучшая val_accuracy: {best_val_acc_e3:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:19:47.175805Z",
     "iopub.status.busy": "2026-02-27T07:19:47.174979Z",
     "iopub.status.idle": "2026-02-27T07:20:44.163069Z",
     "shell.execute_reply": "2026-02-27T07:20:44.162077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший между E2/E3: E3 (val_acc=0.9625)\n",
      "============================================================\n",
      "E4: E3 конфиг + EarlyStopping(patience=5)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 01/30: train_loss=0.3398 train_acc=0.8972 | val_loss=0.2078 val_acc=0.9327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 02/30: train_loss=0.1548 train_acc=0.9520 | val_loss=0.2393 val_acc=0.9228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 03/30: train_loss=0.1028 train_acc=0.9673 | val_loss=0.1652 val_acc=0.9503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 04/30: train_loss=0.0754 train_acc=0.9763 | val_loss=0.1579 val_acc=0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 05/30: train_loss=0.0560 train_acc=0.9812 | val_loss=0.1534 val_acc=0.9556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 06/30: train_loss=0.0441 train_acc=0.9859 | val_loss=0.1565 val_acc=0.9557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 07/30: train_loss=0.0381 train_acc=0.9873 | val_loss=0.1606 val_acc=0.9573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 08/30: train_loss=0.0357 train_acc=0.9882 | val_loss=0.1607 val_acc=0.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 09/30: train_loss=0.0281 train_acc=0.9903 | val_loss=0.1605 val_acc=0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 10/30: train_loss=0.0267 train_acc=0.9913 | val_loss=0.1668 val_acc=0.9587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 11/30: train_loss=0.0233 train_acc=0.9920 | val_loss=0.1682 val_acc=0.9598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 12/30: train_loss=0.0217 train_acc=0.9925 | val_loss=0.1604 val_acc=0.9615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 13/30: train_loss=0.0206 train_acc=0.9934 | val_loss=0.1729 val_acc=0.9614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 14/30: train_loss=0.0188 train_acc=0.9942 | val_loss=0.1690 val_acc=0.9627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 15/30: train_loss=0.0153 train_acc=0.9952 | val_loss=0.1768 val_acc=0.9597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 16/30: train_loss=0.0166 train_acc=0.9950 | val_loss=0.1716 val_acc=0.9617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 17/30: train_loss=0.0158 train_acc=0.9950 | val_loss=0.1752 val_acc=0.9613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 18/30: train_loss=0.0141 train_acc=0.9953 | val_loss=0.1859 val_acc=0.9613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[E4] Epoch 19/30: train_loss=0.0155 train_acc=0.9948 | val_loss=0.1809 val_acc=0.9626\n",
      "  >>> EarlyStopping на эпохе 19, лучшая val_acc=0.9627\n",
      "\n",
      "[E4] Лучшая val_accuracy: 0.9627\n",
      "[E4] Обучение остановлено на эпохе: 19\n",
      "Сохранено: artifacts/best_model.pt\n"
     ]
    }
   ],
   "source": [
    "# ── E4: Лучший из E2/E3 + EarlyStopping ─────────────────────────────────────\n",
    "if best_val_acc_e3 >= best_val_acc_e2:\n",
    "    best_base_tag = 'E3'\n",
    "    e4_dropout_p = 0.0\n",
    "    e4_batchnorm = True\n",
    "else:\n",
    "    best_base_tag = 'E2'\n",
    "    e4_dropout_p = 0.3\n",
    "    e4_batchnorm = False\n",
    "\n",
    "print(f\"Лучший между E2/E3: {best_base_tag} (val_acc={max(best_val_acc_e2, best_val_acc_e3):.4f})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"E4: {best_base_tag} конфиг + EarlyStopping(patience=5)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model_e4 = MLP(\n",
    "    hidden_sizes=[512, 256],\n",
    "    dropout_p=e4_dropout_p,\n",
    "    use_batchnorm=e4_batchnorm\n",
    ").to(device)\n",
    "optimizer_e4 = optim.Adam(model_e4.parameters(), lr=1e-3)\n",
    "es = EarlyStopping(patience=5)\n",
    "\n",
    "history_e4 = run_experiment(\n",
    "    model_e4, train_loader, val_loader, optimizer_e4, criterion, device,\n",
    "    max_epochs=30, early_stopping=es, tag='E4'\n",
    ")\n",
    "\n",
    "best_val_acc_e4 = es.best_val_acc\n",
    "best_val_loss_e4 = history_e4['val_loss'][history_e4['val_acc'].index(max(history_e4['val_acc']))]\n",
    "epochs_e4 = len(history_e4['val_acc'])\n",
    "stopped_epoch = es.stopped_epoch\n",
    "\n",
    "print(f\"\\n[E4] Лучшая val_accuracy: {best_val_acc_e4:.4f}\")\n",
    "print(f\"[E4] Обучение остановлено на эпохе: {stopped_epoch}\")\n",
    "\n",
    "# Сохранить лучшую модель\n",
    "torch.save(model_e4.state_dict(), str(ARTIFACTS_DIR / 'best_model.pt'))\n",
    "print(\"Сохранено: artifacts/best_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2. Часть B (S09): LR, оптимизаторы, weight decay (O1-O3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:20:44.164997Z",
     "iopub.status.busy": "2026-02-27T07:20:44.164799Z",
     "iopub.status.idle": "2026-02-27T07:21:21.597472Z",
     "shell.execute_reply": "2026-02-27T07:21:21.596583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "O1: Adam, lr=0.1 (слишком большой)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O1] Epoch 01/8: train_loss=0.5430 train_acc=0.8390 | val_loss=0.4442 val_acc=0.8685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O1] Epoch 02/8: train_loss=0.3339 train_acc=0.9000 | val_loss=0.2947 val_acc=0.9153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O1] Epoch 03/8: train_loss=0.2727 train_acc=0.9196 | val_loss=0.2418 val_acc=0.9291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O1] Epoch 04/8: train_loss=0.2315 train_acc=0.9308 | val_loss=0.2388 val_acc=0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O1] Epoch 05/8: train_loss=0.2144 train_acc=0.9376 | val_loss=0.2113 val_acc=0.9386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O1] Epoch 06/8: train_loss=0.1938 train_acc=0.9421 | val_loss=0.2131 val_acc=0.9410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O1] Epoch 07/8: train_loss=0.1770 train_acc=0.9492 | val_loss=0.2105 val_acc=0.9440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O1] Epoch 08/8: train_loss=0.1762 train_acc=0.9494 | val_loss=0.2290 val_acc=0.9437\n",
      "\n",
      "[O1] Лучшая val_accuracy: 0.9440\n"
     ]
    }
   ],
   "source": [
    "# Фиксированная архитектура для O1-O3: та же, что E4\n",
    "MAX_EPOCHS_DIAG = 8   # для O1 и O2 — диагностика\n",
    "MAX_EPOCHS_O3   = 15  # для O3\n",
    "\n",
    "# ── O1: Adam, lr слишком большой ─────────────────────────────────────────────\n",
    "print(\"=\" * 60)\n",
    "print(\"O1: Adam, lr=0.1 (слишком большой)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model_o1 = MLP(\n",
    "    hidden_sizes=[512, 256], dropout_p=e4_dropout_p, use_batchnorm=e4_batchnorm\n",
    ").to(device)\n",
    "optimizer_o1 = optim.Adam(model_o1.parameters(), lr=0.1)\n",
    "\n",
    "history_o1 = run_experiment(\n",
    "    model_o1, train_loader, val_loader, optimizer_o1, criterion, device,\n",
    "    max_epochs=MAX_EPOCHS_DIAG, tag='O1'\n",
    ")\n",
    "\n",
    "best_val_acc_o1 = max(history_o1['val_acc'])\n",
    "best_val_loss_o1 = min(history_o1['val_loss'])\n",
    "print(f\"\\n[O1] Лучшая val_accuracy: {best_val_acc_o1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:21:21.598737Z",
     "iopub.status.busy": "2026-02-27T07:21:21.598556Z",
     "iopub.status.idle": "2026-02-27T07:22:04.649206Z",
     "shell.execute_reply": "2026-02-27T07:22:04.647474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "O2: Adam, lr=1e-5 (слишком маленький)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O2] Epoch 01/8: train_loss=1.4373 train_acc=0.6212 | val_loss=0.9747 val_acc=0.7833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O2] Epoch 02/8: train_loss=0.8456 train_acc=0.8028 | val_loss=0.7116 val_acc=0.8319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O2] Epoch 03/8: train_loss=0.6582 train_acc=0.8419 | val_loss=0.5857 val_acc=0.8568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O2] Epoch 04/8: train_loss=0.5521 train_acc=0.8647 | val_loss=0.5010 val_acc=0.8748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O2] Epoch 05/8: train_loss=0.4765 train_acc=0.8812 | val_loss=0.4395 val_acc=0.8898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O2] Epoch 06/8: train_loss=0.4205 train_acc=0.8950 | val_loss=0.3904 val_acc=0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O2] Epoch 07/8: train_loss=0.3745 train_acc=0.9063 | val_loss=0.3571 val_acc=0.9073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O2] Epoch 08/8: train_loss=0.3364 train_acc=0.9150 | val_loss=0.3283 val_acc=0.9169\n",
      "\n",
      "[O2] Лучшая val_accuracy: 0.9169\n"
     ]
    }
   ],
   "source": [
    "# ── O2: Adam, lr слишком маленький ───────────────────────────────────────────\n",
    "print(\"=\" * 60)\n",
    "print(\"O2: Adam, lr=1e-5 (слишком маленький)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model_o2 = MLP(\n",
    "    hidden_sizes=[512, 256], dropout_p=e4_dropout_p, use_batchnorm=e4_batchnorm\n",
    ").to(device)\n",
    "optimizer_o2 = optim.Adam(model_o2.parameters(), lr=1e-5)\n",
    "\n",
    "history_o2 = run_experiment(\n",
    "    model_o2, train_loader, val_loader, optimizer_o2, criterion, device,\n",
    "    max_epochs=MAX_EPOCHS_DIAG, tag='O2'\n",
    ")\n",
    "\n",
    "best_val_acc_o2 = max(history_o2['val_acc'])\n",
    "best_val_loss_o2 = min(history_o2['val_loss'])\n",
    "print(f\"\\n[O2] Лучшая val_accuracy: {best_val_acc_o2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:22:04.651590Z",
     "iopub.status.busy": "2026-02-27T07:22:04.651189Z",
     "iopub.status.idle": "2026-02-27T07:23:06.678633Z",
     "shell.execute_reply": "2026-02-27T07:23:06.678179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "O3: SGD, momentum=0.9, weight_decay=1e-4, lr=0.01\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 01/15: train_loss=0.3679 train_acc=0.8884 | val_loss=0.2017 val_acc=0.9385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 02/15: train_loss=0.1526 train_acc=0.9549 | val_loss=0.1705 val_acc=0.9466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 03/15: train_loss=0.0954 train_acc=0.9710 | val_loss=0.1584 val_acc=0.9523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 04/15: train_loss=0.0635 train_acc=0.9808 | val_loss=0.1418 val_acc=0.9584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 05/15: train_loss=0.0447 train_acc=0.9873 | val_loss=0.1446 val_acc=0.9571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 06/15: train_loss=0.0313 train_acc=0.9916 | val_loss=0.1359 val_acc=0.9599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 07/15: train_loss=0.0260 train_acc=0.9929 | val_loss=0.1469 val_acc=0.9586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 08/15: train_loss=0.0197 train_acc=0.9950 | val_loss=0.1425 val_acc=0.9602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 09/15: train_loss=0.0163 train_acc=0.9962 | val_loss=0.1400 val_acc=0.9614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 10/15: train_loss=0.0128 train_acc=0.9970 | val_loss=0.1452 val_acc=0.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 11/15: train_loss=0.0122 train_acc=0.9971 | val_loss=0.1380 val_acc=0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 12/15: train_loss=0.0105 train_acc=0.9977 | val_loss=0.1486 val_acc=0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 13/15: train_loss=0.0096 train_acc=0.9979 | val_loss=0.1345 val_acc=0.9633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 14/15: train_loss=0.0079 train_acc=0.9984 | val_loss=0.1378 val_acc=0.9627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O3] Epoch 15/15: train_loss=0.0069 train_acc=0.9988 | val_loss=0.1289 val_acc=0.9656\n",
      "\n",
      "[O3] Лучшая val_accuracy: 0.9656\n"
     ]
    }
   ],
   "source": [
    "# ── O3: SGD + momentum + weight_decay ────────────────────────────────────────\n",
    "print(\"=\" * 60)\n",
    "print(\"O3: SGD, momentum=0.9, weight_decay=1e-4, lr=0.01\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "model_o3 = MLP(\n",
    "    hidden_sizes=[512, 256], dropout_p=e4_dropout_p, use_batchnorm=e4_batchnorm\n",
    ").to(device)\n",
    "optimizer_o3 = optim.SGD(\n",
    "    model_o3.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "history_o3 = run_experiment(\n",
    "    model_o3, train_loader, val_loader, optimizer_o3, criterion, device,\n",
    "    max_epochs=MAX_EPOCHS_O3, tag='O3'\n",
    ")\n",
    "\n",
    "best_val_acc_o3 = max(history_o3['val_acc'])\n",
    "best_val_loss_o3 = history_o3['val_loss'][history_o3['val_acc'].index(best_val_acc_o3)]\n",
    "epochs_o3 = len(history_o3['val_acc'])\n",
    "print(f\"\\n[O3] Лучшая val_accuracy: {best_val_acc_o3:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Сохранение артефактов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:23:06.679764Z",
     "iopub.status.busy": "2026-02-27T07:23:06.679649Z",
     "iopub.status.idle": "2026-02-27T07:23:06.685349Z",
     "shell.execute_reply": "2026-02-27T07:23:06.684999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранено: artifacts/runs.csv\n",
      "\n",
      "ID   optimizer lr       momentum  wd       epochs  val_acc    val_loss\n",
      "-----------------------------------------------------------------\n",
      "E1   Adam   0.001              0        15      0.9561     0.1876\n",
      "E2   Adam   0.001              0        15      0.9577     0.1571\n",
      "E3   Adam   0.001              0        15      0.9625     0.157\n",
      "E4   Adam   0.001              0        19      0.9627     0.169\n",
      "O1   Adam   0.1                0        8       0.944      0.2105\n",
      "O2   Adam   1e-05              0        8       0.9169     0.3283\n",
      "O3   SGD    0.01     0.9       0.0001   15      0.9656     0.1289\n"
     ]
    }
   ],
   "source": [
    "# ── runs.csv ─────────────────────────────────────────────────────────────────\n",
    "fieldnames = [\n",
    "    'experiment_id', 'dataset', 'seed', 'model_summary',\n",
    "    'optimizer', 'lr', 'momentum', 'weight_decay',\n",
    "    'epochs_trained', 'best_val_accuracy', 'best_val_loss'\n",
    "]\n",
    "\n",
    "e4_summary = f'512-256, ReLU, {\"+BN\" if e4_batchnorm else \"Dropout(0.3)\"}, EarlyStopping(p=5)'\n",
    "\n",
    "rows = [\n",
    "    dict(experiment_id='E1', dataset='KMNIST', seed=SEED,\n",
    "         model_summary='512-256, ReLU, no-Dropout, no-BN',\n",
    "         optimizer='Adam', lr=1e-3, momentum='', weight_decay=0,\n",
    "         epochs_trained=epochs_e1,\n",
    "         best_val_accuracy=round(best_val_acc_e1, 4),\n",
    "         best_val_loss=round(best_val_loss_e1, 4)),\n",
    "    dict(experiment_id='E2', dataset='KMNIST', seed=SEED,\n",
    "         model_summary='512-256, ReLU, Dropout(0.3), no-BN',\n",
    "         optimizer='Adam', lr=1e-3, momentum='', weight_decay=0,\n",
    "         epochs_trained=epochs_e2,\n",
    "         best_val_accuracy=round(best_val_acc_e2, 4),\n",
    "         best_val_loss=round(best_val_loss_e2, 4)),\n",
    "    dict(experiment_id='E3', dataset='KMNIST', seed=SEED,\n",
    "         model_summary='512-256, ReLU, no-Dropout, BatchNorm',\n",
    "         optimizer='Adam', lr=1e-3, momentum='', weight_decay=0,\n",
    "         epochs_trained=epochs_e3,\n",
    "         best_val_accuracy=round(best_val_acc_e3, 4),\n",
    "         best_val_loss=round(best_val_loss_e3, 4)),\n",
    "    dict(experiment_id='E4', dataset='KMNIST', seed=SEED,\n",
    "         model_summary=e4_summary,\n",
    "         optimizer='Adam', lr=1e-3, momentum='', weight_decay=0,\n",
    "         epochs_trained=epochs_e4,\n",
    "         best_val_accuracy=round(best_val_acc_e4, 4),\n",
    "         best_val_loss=round(best_val_loss_e4, 4)),\n",
    "    dict(experiment_id='O1', dataset='KMNIST', seed=SEED,\n",
    "         model_summary=f'512-256, ReLU, {\"+BN\" if e4_batchnorm else \"Dropout(0.3)\"}',\n",
    "         optimizer='Adam', lr=0.1, momentum='', weight_decay=0,\n",
    "         epochs_trained=len(history_o1['val_acc']),\n",
    "         best_val_accuracy=round(best_val_acc_o1, 4),\n",
    "         best_val_loss=round(best_val_loss_o1, 4)),\n",
    "    dict(experiment_id='O2', dataset='KMNIST', seed=SEED,\n",
    "         model_summary=f'512-256, ReLU, {\"+BN\" if e4_batchnorm else \"Dropout(0.3)\"}',\n",
    "         optimizer='Adam', lr=1e-5, momentum='', weight_decay=0,\n",
    "         epochs_trained=len(history_o2['val_acc']),\n",
    "         best_val_accuracy=round(best_val_acc_o2, 4),\n",
    "         best_val_loss=round(best_val_loss_o2, 4)),\n",
    "    dict(experiment_id='O3', dataset='KMNIST', seed=SEED,\n",
    "         model_summary=f'512-256, ReLU, {\"+BN\" if e4_batchnorm else \"Dropout(0.3)\"}',\n",
    "         optimizer='SGD', lr=0.01, momentum=0.9, weight_decay=1e-4,\n",
    "         epochs_trained=epochs_o3,\n",
    "         best_val_accuracy=round(best_val_acc_o3, 4),\n",
    "         best_val_loss=round(best_val_loss_o3, 4)),\n",
    "]\n",
    "\n",
    "with open(ARTIFACTS_DIR / 'runs.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(\"Сохранено: artifacts/runs.csv\")\n",
    "\n",
    "# Выводим таблицу\n",
    "print(f\"\\n{'ID':<4} {'optimizer':<6} {'lr':<8} {'momentum':<9} {'wd':<8} {'epochs':<7} {'val_acc':<10} {'val_loss'}\")\n",
    "print(\"-\" * 65)\n",
    "for r in rows:\n",
    "    print(f\"{r['experiment_id']:<4} {r['optimizer']:<6} {r['lr']:<8} \"\n",
    "          f\"{str(r['momentum']):<9} {str(r['weight_decay']):<8} {r['epochs_trained']:<7} \"\n",
    "          f\"{r['best_val_accuracy']:<10} {r['best_val_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:23:06.686186Z",
     "iopub.status.busy": "2026-02-27T07:23:06.686081Z",
     "iopub.status.idle": "2026-02-27T07:23:06.689595Z",
     "shell.execute_reply": "2026-02-27T07:23:06.689118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранено: artifacts/best_config.json\n",
      "{\n",
      "  \"dataset\": \"KMNIST\",\n",
      "  \"seed\": 42,\n",
      "  \"model\": {\n",
      "    \"class\": \"MLP\",\n",
      "    \"input_size\": 784,\n",
      "    \"hidden_sizes\": [\n",
      "      512,\n",
      "      256\n",
      "    ],\n",
      "    \"num_classes\": 10,\n",
      "    \"activation\": \"ReLU\",\n",
      "    \"dropout_p\": 0.0,\n",
      "    \"use_batchnorm\": true\n",
      "  },\n",
      "  \"training\": {\n",
      "    \"optimizer\": \"Adam\",\n",
      "    \"lr\": 0.001,\n",
      "    \"weight_decay\": 0,\n",
      "    \"batch_size\": 64,\n",
      "    \"max_epochs\": 30,\n",
      "    \"early_stopping_patience\": 5,\n",
      "    \"epochs_trained\": 19\n",
      "  },\n",
      "  \"results\": {\n",
      "    \"best_val_accuracy\": 0.9627,\n",
      "    \"best_val_loss\": 0.169\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ── best_config.json ──────────────────────────────────────────────────────────\n",
    "best_config = {\n",
    "    'dataset': 'KMNIST',\n",
    "    'seed': SEED,\n",
    "    'model': {\n",
    "        'class': 'MLP',\n",
    "        'input_size': 784,\n",
    "        'hidden_sizes': [512, 256],\n",
    "        'num_classes': 10,\n",
    "        'activation': 'ReLU',\n",
    "        'dropout_p': e4_dropout_p,\n",
    "        'use_batchnorm': e4_batchnorm,\n",
    "    },\n",
    "    'training': {\n",
    "        'optimizer': 'Adam',\n",
    "        'lr': 1e-3,\n",
    "        'weight_decay': 0,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'max_epochs': 30,\n",
    "        'early_stopping_patience': 5,\n",
    "        'epochs_trained': epochs_e4,\n",
    "    },\n",
    "    'results': {\n",
    "        'best_val_accuracy': round(best_val_acc_e4, 4),\n",
    "        'best_val_loss': round(best_val_loss_e4, 4),\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(ARTIFACTS_DIR / 'best_config.json', 'w') as f:\n",
    "    json.dump(best_config, f, indent=2)\n",
    "\n",
    "print(\"Сохранено: artifacts/best_config.json\")\n",
    "print(json.dumps(best_config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Графики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:23:06.690851Z",
     "iopub.status.busy": "2026-02-27T07:23:06.690749Z",
     "iopub.status.idle": "2026-02-27T07:23:06.892766Z",
     "shell.execute_reply": "2026-02-27T07:23:06.892355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранено: artifacts/figures/curves_best.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61501/1805193221.py:23: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ── curves_best.png (E4) ─────────────────────────────────────────────────────\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "epochs_e4_range = range(1, len(history_e4['train_loss']) + 1)\n",
    "\n",
    "ax1.plot(epochs_e4_range, history_e4['train_loss'], label='train loss', marker='o', markersize=3)\n",
    "ax1.plot(epochs_e4_range, history_e4['val_loss'],   label='val loss',   marker='s', markersize=3)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title(f'E4 ({best_base_tag}+EarlyStopping): Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(epochs_e4_range, history_e4['train_acc'], label='train acc', marker='o', markersize=3)\n",
    "ax2.plot(epochs_e4_range, history_e4['val_acc'],   label='val acc',   marker='s', markersize=3)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title(f'E4 ({best_base_tag}+EarlyStopping): Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(FIGURES_DIR / 'curves_best.png'), dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Сохранено: artifacts/figures/curves_best.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:23:06.894705Z",
     "iopub.status.busy": "2026-02-27T07:23:06.894612Z",
     "iopub.status.idle": "2026-02-27T07:23:07.066513Z",
     "shell.execute_reply": "2026-02-27T07:23:07.065624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранено: artifacts/figures/curves_lr_extremes.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61501/3680866422.py:19: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# ── curves_lr_extremes.png (O1, O2) ──────────────────────────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "for ax, hist, label, lr_str in [\n",
    "    (axes[0], history_o1, 'O1: Adam lr=0.1 (слишком большой)', '0.1'),\n",
    "    (axes[1], history_o2, 'O2: Adam lr=1e-5 (слишком маленький)', '1e-5'),\n",
    "]:\n",
    "    ep = range(1, len(hist['train_loss']) + 1)\n",
    "    ax.plot(ep, hist['train_loss'], label='train loss', marker='o', markersize=4)\n",
    "    ax.plot(ep, hist['val_loss'],   label='val loss',   marker='s', markersize=4)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title(label)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(str(FIGURES_DIR / 'curves_lr_extremes.png'), dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Сохранено: artifacts/figures/curves_lr_extremes.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Финальная оценка лучшей модели на тесте (один раз)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-27T07:23:07.069350Z",
     "iopub.status.busy": "2026-02-27T07:23:07.069259Z",
     "iopub.status.idle": "2026-02-27T07:23:07.344961Z",
     "shell.execute_reply": "2026-02-27T07:23:07.344017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Финальная оценка E4 на test-выборке\n",
      "============================================================\n",
      "test_loss     = 0.4476\n",
      "test_accuracy = 0.9116\n",
      "\n",
      "Оценка test-выборки завершена (использована ОДИН РАЗ).\n"
     ]
    }
   ],
   "source": [
    "# Загружаем лучшие веса и оцениваем на test — делается ОДИН РАЗ\n",
    "model_e4.load_state_dict(torch.load(str(ARTIFACTS_DIR / 'best_model.pt'), map_location=device))\n",
    "test_loss, test_acc = evaluate(model_e4, test_loader, criterion, device)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Финальная оценка E4 на test-выборке\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"test_loss     = {test_loss:.4f}\")\n",
    "print(f\"test_accuracy = {test_acc:.4f}\")\n",
    "print(\"\\nОценка test-выборки завершена (использована ОДИН РАЗ).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
