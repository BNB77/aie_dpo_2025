# HW08-09 – PyTorch MLP: регуляризация и оптимизация обучения

## 1. Кратко: что сделано

- Выбран датасет **KMNIST (Вариант A)** — 10 классов рукописных японских символов (каны), 28×28 пикселей, аналог MNIST по сложности, но интереснее тем, что классы визуально схожи.
- В части A (регуляризация) сравнивались: базовый MLP без регуляризации (E1), с Dropout (E2), с BatchNorm (E3), и лучший конфиг с EarlyStopping (E4).
- В части B (оптимизация) диагностировались слишком большой (O1) и слишком маленький (O2) learning rate, а также проверялся SGD+momentum+weight_decay (O3).

## 2. Среда и воспроизводимость

- Python: 3.14
- torch: 2.10.0+cpu
- torchvision: 0.25.0+cpu
- Устройство (CPU/GPU): CPU
- Seed: 42
- Как запустить: открыть `HW08-09.ipynb` и выполнить Run All.

## 3. Данные

- Датасет: **KMNIST** (Вариант A)
- Разделение: train=48000 / val=12000 (80/20 из официального train) + test=10000 (официальный test)
- Трансформации: нормализация в диапазон [-1, 1]: `(x / 255 - 0.5) / 0.5`, реализована в `KMNISTFromNpz`
- Комментарий: KMNIST содержит 10 классов японских символов каны (あ–を). Размерность входа: 784 (28×28×1). Датасет сбалансирован (по 6000 примеров на класс в train). Сложность выше MNIST — некоторые символы визуально похожи, что делает задачу нетривиальной для MLP.

## 4. Базовая модель и обучение

- Модель MLP: 2 скрытых слоя, `784 → 512 → 256 → 10`, активация ReLU
- Loss: CrossEntropyLoss
- Базовый Optimizer (для части A): Adam (lr=1e-3)
- Batch size: 64
- Epochs (макс): 15 (E1-E3), 30 (E4 с EarlyStopping)
- EarlyStopping: patience=5, metric=val_accuracy

## 5. Часть A (S08): регуляризация (E1-E4)

- **E1 (base)**: 512→256, ReLU, без Dropout/BatchNorm. best_val_acc = **0.9561**
- **E2 (Dropout)**: как E1 + Dropout(p=0.3). best_val_acc = **0.9577**
- **E3 (BatchNorm)**: как E1 + BatchNorm после каждого Linear. best_val_acc = **0.9625**
- **E4 (EarlyStopping)**: конфиг E3 (BatchNorm, лучший из E2/E3) + EarlyStopping(patience=5). Остановился на эпохе 19 из 30. best_val_acc = **0.9627**

## 6. Часть B (S09): LR, оптимизаторы, weight decay (O1-O3)

- **O1**: LR слишком большой (Adam, lr=0.1) — обучение нестабильно, loss скачет, финальная val_acc = 0.9440
- **O2**: LR слишком маленький (Adam, lr=1e-5) — обучение почти не идёт, val_acc всего 0.9169 за 8 эпох
- **O3**: SGD, momentum=0.9, weight_decay=1e-4, lr=0.01 — стабильная сходимость, best_val_acc = **0.9656**

## 7. Результаты

Ссылки на файлы в репозитории:

- Таблица результатов: `./artifacts/runs.csv`
- Лучшая модель: `./artifacts/best_model.pt`
- Конфиг лучшей модели: `./artifacts/best_config.json`
- Кривые лучшего прогона: `./artifacts/figures/curves_best.png`
- Кривые "плохих LR": `./artifacts/figures/curves_lr_extremes.png`

Короткая сводка:

- Лучший эксперимент части A: **E4** (BatchNorm + EarlyStopping)
- Лучшая val_accuracy (E4): **0.9627**
- Итоговая test_accuracy (E4): **0.9116**
- Что видно на O1 (слишком большой LR): loss нестабилен, не монотонно убывает, val_acc значительно хуже нормального режима за те же 8 эпох
- Что видно на O2 (слишком маленький LR): loss почти не убывает, val_acc остаётся низкой (0.9169) — обучение практически стоит на месте
- Как повёл себя O3: SGD+momentum+weight_decay показал лучшую val_acc (0.9656), обгоняя E4 (Adam). При этом сходился медленнее в первых эпохах, но дал лучшее качество к 15-й эпохе

## 8. Анализ

На графиках E1 заметен небольшой разрыв между train_acc и val_acc к 10-й эпохе — признак начала переобучения. Dropout (E2) немного сглаживает этот разрыв, но существенного прироста val_acc не даёт — вероятно, p=0.3 слишком мягкий для данной задачи. BatchNorm (E3) помогает значительнее: val_acc вырастает с 0.9561 до 0.9625, а кривые потерь становятся более гладкими — BatchNorm стабилизирует внутренние активации и ускоряет сходимость.

EarlyStopping в E4 остановил обучение на эпохе 19, что разумно: после 15-й эпохи val_accuracy практически не росла, и дальнейшее обучение приводило бы к переобучению. Итоговая val_acc E4 (0.9627) лишь незначительно выше E3 (0.9625) — EarlyStopping в данном случае не улучшил метрику, но предотвратил возможный откат.

O1 показывает типичную картину слишком большого LR: loss скачет между эпохами, val_acc нестабильна — оптимизатор перепрыгивает минимум. O2 — противоположный случай: loss убывает, но крайне медленно; за 8 эпох модель не успевает толком обучиться.

SGD+momentum (O3) с lr=0.01 и weight_decay=1e-4 показал лучший результат (val_acc=0.9656). Это объяснимо: при правильно подобранном lr SGD+momentum глубже оптимизирует задачу, а weight_decay предотвращает взрывной рост весов. Конфиг E4 (Adam, lr=1e-3, BatchNorm) выбран как "лучшая модель" по части A, поскольку именно он обучался в рамках части A с EarlyStopping.

## 9. Итоговый вывод

Лучшим базовым конфигом считаю **E4** (512→256, BatchNorm, Adam, lr=1e-3, EarlyStopping): он автоматически останавливается при отсутствии прогресса и даёт val_acc=0.9627 / test_acc=0.9116. Интересно, что O3 (SGD+momentum) немного выиграл по val_acc — это говорит о том, что при достаточном числе эпох SGD с правильными гиперпараметрами конкурентоспособен. В качестве улучшений стоит попробовать: (1) добавить learning rate scheduler (например, CosineAnnealing), (2) использовать более глубокую архитектуру с Dropout+BatchNorm одновременно.

## 10. Приложение (опционально)

Дополнительных экспериментов не проводилось.
