{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW07 – Кластеризация, внутренние метрики качества, PCA/t-SNE\n",
    "\n",
    "**Студент:** Выполнено в соответствии с заданием к семинару S07  \n",
    "**Цель:** Освоить методы кластеризации (KMeans, DBSCAN, Agglomerative), внутренние метрики качества и визуализацию результатов.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    "    adjusted_rand_score\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Библиотеки загружены успешно\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dataset 01: Разные шкалы + шумовые признаки\n",
    "\n",
    "**Описание:** Числовые признаки в разных шкалах + шумовые признаки. Без масштабирования результаты обычно \"едут\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Загрузка данных и первичный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета 01\n",
    "df1 = pd.read_csv('data/S07-hw-dataset-01.csv')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET 01: Первичный анализ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nРазмер датасета: {df1.shape[0]} строк, {df1.shape[1]} столбцов\\n\")\n",
    "\n",
    "# Первые строки\n",
    "print(\"Первые 5 строк:\")\n",
    "display(df1.head())\n",
    "\n",
    "# Информация о типах данных\n",
    "print(\"\\nИнформация о типах данных:\")\n",
    "df1.info()\n",
    "\n",
    "# Базовые статистики\n",
    "print(\"\\nБазовые статистики:\")\n",
    "display(df1.describe())\n",
    "\n",
    "# Проверка пропусков\n",
    "missing_counts = df1.isnull().sum()\n",
    "missing_pct = (df1.isnull().sum() / len(df1)) * 100\n",
    "missing_df = pd.DataFrame({'Количество': missing_counts, 'Процент': missing_pct})\n",
    "missing_df = missing_df[missing_df['Количество'] > 0]\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"\\nПропуски:\")\n",
    "    display(missing_df)\n",
    "else:\n",
    "    print(\"\\nПропуски: отсутствуют\")\n",
    "\n",
    "# Определение признаков\n",
    "sample_id_1 = df1['sample_id'].values\n",
    "X1 = df1.drop('sample_id', axis=1).values\n",
    "feature_names_1 = df1.drop('sample_id', axis=1).columns.tolist()\n",
    "\n",
    "print(f\"\\nПризнаки для кластеризации: {feature_names_1}\")\n",
    "print(f\"Размерность X: {X1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 01: только числовые признаки, применяем StandardScaler\n",
    "scaler_1 = StandardScaler()\n",
    "X1_scaled = scaler_1.fit_transform(X1)\n",
    "\n",
    "print(\"Dataset 01: Препроцессинг завершен\")\n",
    "print(f\"Форма после масштабирования: {X1_scaled.shape}\")\n",
    "print(f\"Среднее по столбцам: {X1_scaled.mean(axis=0).round(6)}\")\n",
    "print(f\"Стандартное отклонение: {X1_scaled.std(axis=0).round(6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. KMeans: подбор k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор k для KMeans на датасете 01\n",
    "k_range = range(2, 21)\n",
    "silhouette_scores_1 = []\n",
    "db_scores_1 = []\n",
    "ch_scores_1 = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X1_scaled)\n",
    "    \n",
    "    sil = silhouette_score(X1_scaled, labels)\n",
    "    db = davies_bouldin_score(X1_scaled, labels)\n",
    "    ch = calinski_harabasz_score(X1_scaled, labels)\n",
    "    \n",
    "    silhouette_scores_1.append(sil)\n",
    "    db_scores_1.append(db)\n",
    "    ch_scores_1.append(ch)\n",
    "\n",
    "# Визуализация метрик vs k\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].plot(k_range, silhouette_scores_1, marker='o', color='blue')\n",
    "axes[0].set_xlabel('Количество кластеров k')\n",
    "axes[0].set_ylabel('Silhouette Score')\n",
    "axes[0].set_title('Dataset 01: Silhouette Score vs k (KMeans)')\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(k_range, db_scores_1, marker='o', color='red')\n",
    "axes[1].set_xlabel('Количество кластеров k')\n",
    "axes[1].set_ylabel('Davies-Bouldin Score')\n",
    "axes[1].set_title('Dataset 01: Davies-Bouldin Score vs k (KMeans)')\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].plot(k_range, ch_scores_1, marker='o', color='green')\n",
    "axes[2].set_xlabel('Количество кластеров k')\n",
    "axes[2].set_ylabel('Calinski-Harabasz Score')\n",
    "axes[2].set_title('Dataset 01: Calinski-Harabasz Score vs k (KMeans)')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/ds01_kmeans_metrics_vs_k.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Выбор лучшего k\n",
    "best_k_1 = k_range[np.argmax(silhouette_scores_1)]\n",
    "print(f\"\\nЛучшее значение k по Silhouette Score: {best_k_1}\")\n",
    "print(f\"Silhouette Score: {max(silhouette_scores_1):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. DBSCAN: подбор eps и min_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор eps для DBSCAN на датасете 01\n",
    "eps_range = np.arange(0.3, 2.0, 0.1)\n",
    "min_samples_values = [3, 5, 10]\n",
    "\n",
    "dbscan_results_1 = []\n",
    "\n",
    "for min_samp in min_samples_values:\n",
    "    for eps in eps_range:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samp)\n",
    "        labels = dbscan.fit_predict(X1_scaled)\n",
    "        \n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = list(labels).count(-1)\n",
    "        noise_pct = n_noise / len(labels) * 100\n",
    "        \n",
    "        # Метрики только если есть хотя бы 2 кластера и не все точки - шум\n",
    "        if n_clusters >= 2 and n_noise < len(labels) - 1:\n",
    "            # Метрики считаем только на non-noise точках\n",
    "            non_noise_mask = labels != -1\n",
    "            if non_noise_mask.sum() > 1:\n",
    "                sil = silhouette_score(X1_scaled[non_noise_mask], labels[non_noise_mask])\n",
    "                db = davies_bouldin_score(X1_scaled[non_noise_mask], labels[non_noise_mask])\n",
    "                ch = calinski_harabasz_score(X1_scaled[non_noise_mask], labels[non_noise_mask])\n",
    "                \n",
    "                dbscan_results_1.append({\n",
    "                    'eps': eps,\n",
    "                    'min_samples': min_samp,\n",
    "                    'n_clusters': n_clusters,\n",
    "                    'noise_pct': noise_pct,\n",
    "                    'silhouette': sil,\n",
    "                    'davies_bouldin': db,\n",
    "                    'calinski_harabasz': ch\n",
    "                })\n",
    "\n",
    "# Лучший результат по silhouette\n",
    "if len(dbscan_results_1) > 0:\n",
    "    dbscan_df_1 = pd.DataFrame(dbscan_results_1)\n",
    "    best_dbscan_1 = dbscan_df_1.loc[dbscan_df_1['silhouette'].idxmax()]\n",
    "    \n",
    "    print(\"\\nЛучший результат DBSCAN на Dataset 01:\")\n",
    "    print(f\"eps = {best_dbscan_1['eps']:.2f}, min_samples = {int(best_dbscan_1['min_samples'])}\")\n",
    "    print(f\"Количество кластеров: {int(best_dbscan_1['n_clusters'])}\")\n",
    "    print(f\"Доля шума: {best_dbscan_1['noise_pct']:.2f}%\")\n",
    "    print(f\"Silhouette: {best_dbscan_1['silhouette']:.4f}\")\n",
    "    print(f\"Davies-Bouldin: {best_dbscan_1['davies_bouldin']:.4f}\")\n",
    "    print(f\"Calinski-Harabasz: {best_dbscan_1['calinski_harabasz']:.2f}\")\n",
    "else:\n",
    "    print(\"\\nНе удалось найти подходящие параметры DBSCAN для Dataset 01\")\n",
    "    best_dbscan_1 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Финальная модель и визуализация для Dataset 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем лучшую модель (KMeans с лучшим k)\n",
    "best_model_1 = KMeans(n_clusters=best_k_1, random_state=42, n_init=10)\n",
    "labels_1 = best_model_1.fit_predict(X1_scaled)\n",
    "\n",
    "# Метрики для лучшей модели\n",
    "sil_1 = silhouette_score(X1_scaled, labels_1)\n",
    "db_1 = davies_bouldin_score(X1_scaled, labels_1)\n",
    "ch_1 = calinski_harabasz_score(X1_scaled, labels_1)\n",
    "\n",
    "print(f\"\\nФинальная модель для Dataset 01: KMeans с k={best_k_1}\")\n",
    "print(f\"Silhouette Score: {sil_1:.4f}\")\n",
    "print(f\"Davies-Bouldin Score: {db_1:.4f}\")\n",
    "print(f\"Calinski-Harabasz Score: {ch_1:.2f}\")\n",
    "\n",
    "# PCA для визуализации\n",
    "pca_1 = PCA(n_components=2, random_state=42)\n",
    "X1_pca = pca_1.fit_transform(X1_scaled)\n",
    "\n",
    "# Визуализация PCA\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X1_pca[:, 0], X1_pca[:, 1], c=labels_1, cmap='viridis', s=30, alpha=0.7)\n",
    "plt.colorbar(scatter, label='Кластер')\n",
    "plt.xlabel(f'PC1 (объясненная дисперсия: {pca_1.explained_variance_ratio_[0]:.2%})')\n",
    "plt.ylabel(f'PC2 (объясненная дисперсия: {pca_1.explained_variance_ratio_[1]:.2%})')\n",
    "plt.title(f'Dataset 01: PCA визуализация (KMeans, k={best_k_1})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('artifacts/figures/ds01_pca_best_solution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Сохранение меток кластеров\n",
    "labels_df_1 = pd.DataFrame({\n",
    "    'sample_id': sample_id_1,\n",
    "    'cluster_label': labels_1\n",
    "})\n",
    "labels_df_1.to_csv('artifacts/labels/labels_hw07_ds1.csv', index=False)\n",
    "print(\"\\nМетки кластеров сохранены в artifacts/labels/labels_hw07_ds1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Итог по Dataset 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоги по Dataset 01:**\n",
    "\n",
    "Dataset 01 содержит числовые признаки в разных шкалах, что делает масштабирование критически важным. Без StandardScaler результаты были бы искажены из-за доминирования признаков с большими значениями.\n",
    "\n",
    "**KMeans** показал хорошие результаты после подбора оптимального k. Метрика Silhouette Score помогла выбрать разумное количество кластеров, балансирующее между компактностью кластеров и их разделением.\n",
    "\n",
    "**DBSCAN** на этом датасете показал себя менее стабильно - при многих значениях eps либо образовывался один большой кластер, либо слишком много шума. Это связано с относительно однородной плотностью данных и отсутствием явных плотностных групп.\n",
    "\n",
    "**Основные сложности:**\n",
    "- Необходимость масштабирования из-за разных шкал признаков\n",
    "- Определение оптимального количества кластеров при отсутствии явной структуры\n",
    "- Влияние шумовых признаков на качество кластеризации\n",
    "\n",
    "**Выбранный метод:** KMeans с подобранным k наиболее уместен для данного датасета, так как данные имеют относительно сферическую структуру и равномерную плотность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dataset 02: Нелинейная структура + выбросы\n",
    "\n",
    "**Описание:** Нелинейная структура + выбросы + лишний шумовой признак. Хорошо демонстрирует, где KMeans проигрывает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Загрузка данных и первичный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета 02\n",
    "df2 = pd.read_csv('data/S07-hw-dataset-02.csv')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET 02: Первичный анализ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nРазмер датасета: {df2.shape[0]} строк, {df2.shape[1]} столбцов\\n\")\n",
    "\n",
    "print(\"Первые 5 строк:\")\n",
    "display(df2.head())\n",
    "\n",
    "print(\"\\nИнформация о типах данных:\")\n",
    "df2.info()\n",
    "\n",
    "print(\"\\nБазовые статистики:\")\n",
    "display(df2.describe())\n",
    "\n",
    "# Проверка пропусков\n",
    "missing_counts = df2.isnull().sum()\n",
    "missing_pct = (df2.isnull().sum() / len(df2)) * 100\n",
    "missing_df = pd.DataFrame({'Количество': missing_counts, 'Процент': missing_pct})\n",
    "missing_df = missing_df[missing_df['Количество'] > 0]\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"\\nПропуски:\")\n",
    "    display(missing_df)\n",
    "else:\n",
    "    print(\"\\nПропуски: отсутствуют\")\n",
    "\n",
    "# Определение признаков\n",
    "sample_id_2 = df2['sample_id'].values\n",
    "X2 = df2.drop('sample_id', axis=1).values\n",
    "feature_names_2 = df2.drop('sample_id', axis=1).columns.tolist()\n",
    "\n",
    "print(f\"\\nПризнаки для кластеризации: {feature_names_2}\")\n",
    "print(f\"Размерность X: {X2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 02: только числовые признаки, применяем StandardScaler\n",
    "scaler_2 = StandardScaler()\n",
    "X2_scaled = scaler_2.fit_transform(X2)\n",
    "\n",
    "print(\"Dataset 02: Препроцессинг завершен\")\n",
    "print(f\"Форма после масштабирования: {X2_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. KMeans: подбор k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор k для KMeans на датасете 02\n",
    "k_range = range(2, 21)\n",
    "silhouette_scores_2 = []\n",
    "db_scores_2 = []\n",
    "ch_scores_2 = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X2_scaled)\n",
    "    \n",
    "    sil = silhouette_score(X2_scaled, labels)\n",
    "    db = davies_bouldin_score(X2_scaled, labels)\n",
    "    ch = calinski_harabasz_score(X2_scaled, labels)\n",
    "    \n",
    "    silhouette_scores_2.append(sil)\n",
    "    db_scores_2.append(db)\n",
    "    ch_scores_2.append(ch)\n",
    "\n",
    "# Визуализация метрик vs k\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].plot(k_range, silhouette_scores_2, marker='o', color='blue')\n",
    "axes[0].set_xlabel('Количество кластеров k')\n",
    "axes[0].set_ylabel('Silhouette Score')\n",
    "axes[0].set_title('Dataset 02: Silhouette Score vs k (KMeans)')\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(k_range, db_scores_2, marker='o', color='red')\n",
    "axes[1].set_xlabel('Количество кластеров k')\n",
    "axes[1].set_ylabel('Davies-Bouldin Score')\n",
    "axes[1].set_title('Dataset 02: Davies-Bouldin Score vs k (KMeans)')\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].plot(k_range, ch_scores_2, marker='o', color='green')\n",
    "axes[2].set_xlabel('Количество кластеров k')\n",
    "axes[2].set_ylabel('Calinski-Harabasz Score')\n",
    "axes[2].set_title('Dataset 02: Calinski-Harabasz Score vs k (KMeans)')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/ds02_kmeans_metrics_vs_k.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "best_k_2 = k_range[np.argmax(silhouette_scores_2)]\n",
    "print(f\"\\nЛучшее значение k по Silhouette Score: {best_k_2}\")\n",
    "print(f\"Silhouette Score: {max(silhouette_scores_2):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. DBSCAN: подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор eps для DBSCAN на датасете 02\n",
    "eps_range = np.arange(0.2, 2.5, 0.1)\n",
    "min_samples_values = [3, 5, 10]\n",
    "\n",
    "dbscan_results_2 = []\n",
    "\n",
    "for min_samp in min_samples_values:\n",
    "    for eps in eps_range:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samp)\n",
    "        labels = dbscan.fit_predict(X2_scaled)\n",
    "        \n",
    "        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        n_noise = list(labels).count(-1)\n",
    "        noise_pct = n_noise / len(labels) * 100\n",
    "        \n",
    "        if n_clusters >= 2 and n_noise < len(labels) - 1:\n",
    "            non_noise_mask = labels != -1\n",
    "            if non_noise_mask.sum() > 1:\n",
    "                sil = silhouette_score(X2_scaled[non_noise_mask], labels[non_noise_mask])\n",
    "                db = davies_bouldin_score(X2_scaled[non_noise_mask], labels[non_noise_mask])\n",
    "                ch = calinski_harabasz_score(X2_scaled[non_noise_mask], labels[non_noise_mask])\n",
    "                \n",
    "                dbscan_results_2.append({\n",
    "                    'eps': eps,\n",
    "                    'min_samples': min_samp,\n",
    "                    'n_clusters': n_clusters,\n",
    "                    'noise_pct': noise_pct,\n",
    "                    'silhouette': sil,\n",
    "                    'davies_bouldin': db,\n",
    "                    'calinski_harabasz': ch\n",
    "                })\n",
    "\n",
    "if len(dbscan_results_2) > 0:\n",
    "    dbscan_df_2 = pd.DataFrame(dbscan_results_2)\n",
    "    best_dbscan_2 = dbscan_df_2.loc[dbscan_df_2['silhouette'].idxmax()]\n",
    "    \n",
    "    print(\"\\nЛучший результат DBSCAN на Dataset 02:\")\n",
    "    print(f\"eps = {best_dbscan_2['eps']:.2f}, min_samples = {int(best_dbscan_2['min_samples'])}\")\n",
    "    print(f\"Количество кластеров: {int(best_dbscan_2['n_clusters'])}\")\n",
    "    print(f\"Доля шума: {best_dbscan_2['noise_pct']:.2f}%\")\n",
    "    print(f\"Silhouette: {best_dbscan_2['silhouette']:.4f}\")\n",
    "    print(f\"Davies-Bouldin: {best_dbscan_2['davies_bouldin']:.4f}\")\n",
    "    print(f\"Calinski-Harabasz: {best_dbscan_2['calinski_harabasz']:.2f}\")\n",
    "else:\n",
    "    print(\"\\nНе удалось найти подходящие параметры DBSCAN для Dataset 02\")\n",
    "    best_dbscan_2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Сравнение KMeans и DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Финальные модели для сравнения\n",
    "kmeans_2 = KMeans(n_clusters=best_k_2, random_state=42, n_init=10)\n",
    "labels_kmeans_2 = kmeans_2.fit_predict(X2_scaled)\n",
    "\n",
    "sil_kmeans_2 = silhouette_score(X2_scaled, labels_kmeans_2)\n",
    "db_kmeans_2 = davies_bouldin_score(X2_scaled, labels_kmeans_2)\n",
    "ch_kmeans_2 = calinski_harabasz_score(X2_scaled, labels_kmeans_2)\n",
    "\n",
    "print(f\"\\nKMeans (k={best_k_2}):\")\n",
    "print(f\"  Silhouette: {sil_kmeans_2:.4f}\")\n",
    "print(f\"  Davies-Bouldin: {db_kmeans_2:.4f}\")\n",
    "print(f\"  Calinski-Harabasz: {ch_kmeans_2:.2f}\")\n",
    "\n",
    "if best_dbscan_2 is not None:\n",
    "    dbscan_2 = DBSCAN(eps=best_dbscan_2['eps'], min_samples=int(best_dbscan_2['min_samples']))\n",
    "    labels_dbscan_2 = dbscan_2.fit_predict(X2_scaled)\n",
    "    \n",
    "    print(f\"\\nDBSCAN (eps={best_dbscan_2['eps']:.2f}, min_samples={int(best_dbscan_2['min_samples'])}):\")\n",
    "    print(f\"  Silhouette: {best_dbscan_2['silhouette']:.4f}\")\n",
    "    print(f\"  Davies-Bouldin: {best_dbscan_2['davies_bouldin']:.4f}\")\n",
    "    print(f\"  Calinski-Harabasz: {best_dbscan_2['calinski_harabasz']:.2f}\")\n",
    "    print(f\"  Доля шума: {best_dbscan_2['noise_pct']:.2f}%\")\n",
    "    \n",
    "    # Выбираем лучшую модель по silhouette\n",
    "    if best_dbscan_2['silhouette'] > sil_kmeans_2:\n",
    "        print(\"\\n→ DBSCAN показывает лучший результат для Dataset 02\")\n",
    "        labels_2 = labels_dbscan_2\n",
    "        best_method_2 = \"DBSCAN\"\n",
    "    else:\n",
    "        print(\"\\n→ KMeans показывает лучший результат для Dataset 02\")\n",
    "        labels_2 = labels_kmeans_2\n",
    "        best_method_2 = \"KMeans\"\n",
    "else:\n",
    "    print(\"\\n→ KMeans - единственная подходящая модель для Dataset 02\")\n",
    "    labels_2 = labels_kmeans_2\n",
    "    best_method_2 = \"KMeans\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Визуализация для Dataset 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA для визуализации\n",
    "pca_2 = PCA(n_components=2, random_state=42)\n",
    "X2_pca = pca_2.fit_transform(X2_scaled)\n",
    "\n",
    "# Визуализация лучшего решения\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X2_pca[:, 0], X2_pca[:, 1], c=labels_2, cmap='viridis', s=30, alpha=0.7)\n",
    "plt.colorbar(scatter, label='Кластер')\n",
    "plt.xlabel(f'PC1 (объясненная дисперсия: {pca_2.explained_variance_ratio_[0]:.2%})')\n",
    "plt.ylabel(f'PC2 (объясненная дисперсия: {pca_2.explained_variance_ratio_[1]:.2%})')\n",
    "plt.title(f'Dataset 02: PCA визуализация ({best_method_2})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('artifacts/figures/ds02_pca_best_solution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Сравнительная визуализация KMeans vs DBSCAN\n",
    "if best_dbscan_2 is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    scatter1 = axes[0].scatter(X2_pca[:, 0], X2_pca[:, 1], c=labels_kmeans_2, cmap='viridis', s=30, alpha=0.7)\n",
    "    axes[0].set_xlabel(f'PC1')\n",
    "    axes[0].set_ylabel(f'PC2')\n",
    "    axes[0].set_title(f'Dataset 02: KMeans (k={best_k_2})')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter1, ax=axes[0], label='Кластер')\n",
    "    \n",
    "    scatter2 = axes[1].scatter(X2_pca[:, 0], X2_pca[:, 1], c=labels_dbscan_2, cmap='viridis', s=30, alpha=0.7)\n",
    "    axes[1].set_xlabel(f'PC1')\n",
    "    axes[1].set_ylabel(f'PC2')\n",
    "    axes[1].set_title(f'Dataset 02: DBSCAN (eps={best_dbscan_2[\"eps\"]:.2f})')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    plt.colorbar(scatter2, ax=axes[1], label='Кластер')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('artifacts/figures/ds02_comparison_kmeans_vs_dbscan.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Сохранение меток кластеров\n",
    "labels_df_2 = pd.DataFrame({\n",
    "    'sample_id': sample_id_2,\n",
    "    'cluster_label': labels_2\n",
    "})\n",
    "labels_df_2.to_csv('artifacts/labels/labels_hw07_ds2.csv', index=False)\n",
    "print(\"\\nМетки кластеров сохранены в artifacts/labels/labels_hw07_ds2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. Итог по Dataset 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоги по Dataset 02:**\n",
    "\n",
    "Dataset 02 характеризуется нелинейной структурой кластеров, наличием выбросов и шумовых признаков. Это классический пример, где KMeans может показывать ограничения из-за предположения о сферической форме кластеров.\n",
    "\n",
    "**KMeans** на этом датасете работает, но может \"разрезать\" нелинейные структуры на несколько сферических кластеров, что не всегда соответствует истинной структуре данных.\n",
    "\n",
    "**DBSCAN** здесь показывает свои сильные стороны:\n",
    "- Способность обнаруживать кластеры произвольной формы\n",
    "- Автоматическая идентификация выбросов как шума\n",
    "- Меньшая чувствительность к нелинейным зависимостям\n",
    "\n",
    "**Основные сложности:**\n",
    "- Выбор правильного eps для DBSCAN критичен - слишком малое значение создает много шума, слишком большое объединяет все в один кластер\n",
    "- Наличие выбросов влияет на центроиды KMeans\n",
    "- Шумовые признаки снижают качество разделения\n",
    "\n",
    "**Выбранный метод:** Для Dataset 02 DBSCAN (если показал лучшие метрики) более уместен благодаря способности обрабатывать нелинейные структуры и выделять выбросы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Dataset 03: Кластеры разной плотности + шум\n",
    "\n",
    "**Описание:** Кластеры разной плотности + фоновый шум. Часто провоцирует ошибки выбора eps для DBSCAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Загрузка данных и первичный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета 03\n",
    "df3 = pd.read_csv('data/S07-hw-dataset-03.csv')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET 03: Первичный анализ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nРазмер датасета: {df3.shape[0]} строк, {df3.shape[1]} столбцов\\n\")\n",
    "\n",
    "print(\"Первые 5 строк:\")\n",
    "display(df3.head())\n",
    "\n",
    "print(\"\\nИнформация о типах данных:\")\n",
    "df3.info()\n",
    "\n",
    "print(\"\\nБазовые статистики:\")\n",
    "display(df3.describe())\n",
    "\n",
    "# Проверка пропусков\n",
    "missing_counts = df3.isnull().sum()\n",
    "missing_pct = (df3.isnull().sum() / len(df3)) * 100\n",
    "missing_df = pd.DataFrame({'Количество': missing_counts, 'Процент': missing_pct})\n",
    "missing_df = missing_df[missing_df['Количество'] > 0]\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"\\nПропуски:\")\n",
    "    display(missing_df)\n",
    "else:\n",
    "    print(\"\\nПропуски: отсутствуют\")\n",
    "\n",
    "# Определение признаков\n",
    "sample_id_3 = df3['sample_id'].values\n",
    "X3 = df3.drop('sample_id', axis=1).values\n",
    "feature_names_3 = df3.drop('sample_id', axis=1).columns.tolist()\n",
    "\n",
    "print(f\"\\nПризнаки для кластеризации: {feature_names_3}\")\n",
    "print(f\"Размерность X: {X3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 03: только числовые признаки, применяем StandardScaler\n",
    "scaler_3 = StandardScaler()\n",
    "X3_scaled = scaler_3.fit_transform(X3)\n",
    "\n",
    "print(\"Dataset 03: Препроцессинг завершен\")\n",
    "print(f\"Форма после масштабирования: {X3_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. KMeans: подбор k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор k для KMeans на датасете 03\n",
    "k_range = range(2, 21)\n",
    "silhouette_scores_3 = []\n",
    "db_scores_3 = []\n",
    "ch_scores_3 = []\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X3_scaled)\n",
    "    \n",
    "    sil = silhouette_score(X3_scaled, labels)\n",
    "    db = davies_bouldin_score(X3_scaled, labels)\n",
    "    ch = calinski_harabasz_score(X3_scaled, labels)\n",
    "    \n",
    "    silhouette_scores_3.append(sil)\n",
    "    db_scores_3.append(db)\n",
    "    ch_scores_3.append(ch)\n",
    "\n",
    "# Визуализация метрик vs k\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].plot(k_range, silhouette_scores_3, marker='o', color='blue')\n",
    "axes[0].set_xlabel('Количество кластеров k')\n",
    "axes[0].set_ylabel('Silhouette Score')\n",
    "axes[0].set_title('Dataset 03: Silhouette Score vs k (KMeans)')\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(k_range, db_scores_3, marker='o', color='red')\n",
    "axes[1].set_xlabel('Количество кластеров k')\n",
    "axes[1].set_ylabel('Davies-Bouldin Score')\n",
    "axes[1].set_title('Dataset 03: Davies-Bouldin Score vs k (KMeans)')\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].plot(k_range, ch_scores_3, marker='o', color='green')\n",
    "axes[2].set_xlabel('Количество кластеров k')\n",
    "axes[2].set_ylabel('Calinski-Harabasz Score')\n",
    "axes[2].set_title('Dataset 03: Calinski-Harabasz Score vs k (KMeans)')\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/ds03_kmeans_metrics_vs_k.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "best_k_3 = k_range[np.argmax(silhouette_scores_3)]\n",
    "print(f\"\\nЛучшее значение k по Silhouette Score: {best_k_3}\")\n",
    "print(f\"Silhouette Score: {max(silhouette_scores_3):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Agglomerative Clustering: подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор параметров для Agglomerative Clustering на датасете 03\n",
    "linkage_methods = ['ward', 'complete', 'average']\n",
    "k_range_agg = range(2, 16)\n",
    "\n",
    "agg_results_3 = []\n",
    "\n",
    "for linkage in linkage_methods:\n",
    "    for k in k_range_agg:\n",
    "        agg = AgglomerativeClustering(n_clusters=k, linkage=linkage)\n",
    "        labels = agg.fit_predict(X3_scaled)\n",
    "        \n",
    "        sil = silhouette_score(X3_scaled, labels)\n",
    "        db = davies_bouldin_score(X3_scaled, labels)\n",
    "        ch = calinski_harabasz_score(X3_scaled, labels)\n",
    "        \n",
    "        agg_results_3.append({\n",
    "            'linkage': linkage,\n",
    "            'n_clusters': k,\n",
    "            'silhouette': sil,\n",
    "            'davies_bouldin': db,\n",
    "            'calinski_harabasz': ch\n",
    "        })\n",
    "\n",
    "agg_df_3 = pd.DataFrame(agg_results_3)\n",
    "best_agg_3 = agg_df_3.loc[agg_df_3['silhouette'].idxmax()]\n",
    "\n",
    "print(\"\\nЛучший результат Agglomerative Clustering на Dataset 03:\")\n",
    "print(f\"linkage = {best_agg_3['linkage']}, n_clusters = {int(best_agg_3['n_clusters'])}\")\n",
    "print(f\"Silhouette: {best_agg_3['silhouette']:.4f}\")\n",
    "print(f\"Davies-Bouldin: {best_agg_3['davies_bouldin']:.4f}\")\n",
    "print(f\"Calinski-Harabasz: {best_agg_3['calinski_harabasz']:.2f}\")\n",
    "\n",
    "# Визуализация сравнения linkage методов\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for linkage in linkage_methods:\n",
    "    subset = agg_df_3[agg_df_3['linkage'] == linkage]\n",
    "    axes[0].plot(subset['n_clusters'], subset['silhouette'], marker='o', label=linkage)\n",
    "    axes[1].plot(subset['n_clusters'], subset['davies_bouldin'], marker='o', label=linkage)\n",
    "    axes[2].plot(subset['n_clusters'], subset['calinski_harabasz'], marker='o', label=linkage)\n",
    "\n",
    "axes[0].set_xlabel('Количество кластеров k')\n",
    "axes[0].set_ylabel('Silhouette Score')\n",
    "axes[0].set_title('Dataset 03: Silhouette vs k (Agglomerative)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].set_xlabel('Количество кластеров k')\n",
    "axes[1].set_ylabel('Davies-Bouldin Score')\n",
    "axes[1].set_title('Dataset 03: Davies-Bouldin vs k (Agglomerative)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "axes[2].set_xlabel('Количество кластеров k')\n",
    "axes[2].set_ylabel('Calinski-Harabasz Score')\n",
    "axes[2].set_title('Dataset 03: Calinski-Harabasz vs k (Agglomerative)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/ds03_agglomerative_linkage_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Сравнение методов и выбор лучшего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Финальные модели для сравнения\n",
    "kmeans_3 = KMeans(n_clusters=best_k_3, random_state=42, n_init=10)\n",
    "labels_kmeans_3 = kmeans_3.fit_predict(X3_scaled)\n",
    "\n",
    "sil_kmeans_3 = silhouette_score(X3_scaled, labels_kmeans_3)\n",
    "db_kmeans_3 = davies_bouldin_score(X3_scaled, labels_kmeans_3)\n",
    "ch_kmeans_3 = calinski_harabasz_score(X3_scaled, labels_kmeans_3)\n",
    "\n",
    "agg_3 = AgglomerativeClustering(\n",
    "    n_clusters=int(best_agg_3['n_clusters']), \n",
    "    linkage=best_agg_3['linkage']\n",
    ")\n",
    "labels_agg_3 = agg_3.fit_predict(X3_scaled)\n",
    "\n",
    "print(\"\\nСравнение методов на Dataset 03:\")\n",
    "print(f\"\\nKMeans (k={best_k_3}):\")\n",
    "print(f\"  Silhouette: {sil_kmeans_3:.4f}\")\n",
    "print(f\"  Davies-Bouldin: {db_kmeans_3:.4f}\")\n",
    "print(f\"  Calinski-Harabasz: {ch_kmeans_3:.2f}\")\n",
    "\n",
    "print(f\"\\nAgglomerative (linkage={best_agg_3['linkage']}, k={int(best_agg_3['n_clusters'])}):\")\n",
    "print(f\"  Silhouette: {best_agg_3['silhouette']:.4f}\")\n",
    "print(f\"  Davies-Bouldin: {best_agg_3['davies_bouldin']:.4f}\")\n",
    "print(f\"  Calinski-Harabasz: {best_agg_3['calinski_harabasz']:.2f}\")\n",
    "\n",
    "# Выбираем лучшую модель\n",
    "if best_agg_3['silhouette'] > sil_kmeans_3:\n",
    "    print(\"\\n→ Agglomerative Clustering показывает лучший результат для Dataset 03\")\n",
    "    labels_3 = labels_agg_3\n",
    "    best_method_3 = \"Agglomerative\"\n",
    "else:\n",
    "    print(\"\\n→ KMeans показывает лучший результат для Dataset 03\")\n",
    "    labels_3 = labels_kmeans_3\n",
    "    best_method_3 = \"KMeans\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Визуализация для Dataset 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA для визуализации\n",
    "pca_3 = PCA(n_components=2, random_state=42)\n",
    "X3_pca = pca_3.fit_transform(X3_scaled)\n",
    "\n",
    "# Визуализация лучшего решения\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X3_pca[:, 0], X3_pca[:, 1], c=labels_3, cmap='viridis', s=30, alpha=0.7)\n",
    "plt.colorbar(scatter, label='Кластер')\n",
    "plt.xlabel(f'PC1 (объясненная дисперсия: {pca_3.explained_variance_ratio_[0]:.2%})')\n",
    "plt.ylabel(f'PC2 (объясненная дисперсия: {pca_3.explained_variance_ratio_[1]:.2%})')\n",
    "plt.title(f'Dataset 03: PCA визуализация ({best_method_3})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('artifacts/figures/ds03_pca_best_solution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Сохранение меток кластеров\n",
    "labels_df_3 = pd.DataFrame({\n",
    "    'sample_id': sample_id_3,\n",
    "    'cluster_label': labels_3\n",
    "})\n",
    "labels_df_3.to_csv('artifacts/labels/labels_hw07_ds3.csv', index=False)\n",
    "print(\"\\nМетки кластеров сохранены в artifacts/labels/labels_hw07_ds3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7. Проверка устойчивости (Dataset 03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка устойчивости KMeans на Dataset 03\n",
    "print(\"=\" * 60)\n",
    "print(\"ПРОВЕРКА УСТОЙЧИВОСТИ (Dataset 03)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_runs = 5\n",
    "random_states = [42, 123, 456, 789, 999]\n",
    "stability_results = []\n",
    "\n",
    "# Сохраняем все разбиения\n",
    "all_labels = []\n",
    "\n",
    "for i, rs in enumerate(random_states):\n",
    "    kmeans = KMeans(n_clusters=best_k_3, random_state=rs, n_init=10)\n",
    "    labels = kmeans.fit_predict(X3_scaled)\n",
    "    all_labels.append(labels)\n",
    "    \n",
    "    sil = silhouette_score(X3_scaled, labels)\n",
    "    db = davies_bouldin_score(X3_scaled, labels)\n",
    "    ch = calinski_harabasz_score(X3_scaled, labels)\n",
    "    \n",
    "    stability_results.append({\n",
    "        'run': i + 1,\n",
    "        'random_state': rs,\n",
    "        'silhouette': sil,\n",
    "        'davies_bouldin': db,\n",
    "        'calinski_harabasz': ch\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nЗапуск {i+1} (random_state={rs}):\")\n",
    "    print(f\"  Silhouette: {sil:.4f}\")\n",
    "    print(f\"  Davies-Bouldin: {db:.4f}\")\n",
    "    print(f\"  Calinski-Harabasz: {ch:.2f}\")\n",
    "\n",
    "# Вычисляем ARI между всеми парами разбиений\n",
    "print(\"\\nСравнение разбиений (Adjusted Rand Index):\")\n",
    "ari_scores = []\n",
    "for i in range(n_runs):\n",
    "    for j in range(i + 1, n_runs):\n",
    "        ari = adjusted_rand_score(all_labels[i], all_labels[j])\n",
    "        ari_scores.append(ari)\n",
    "        print(f\"  Запуск {i+1} vs Запуск {j+1}: ARI = {ari:.4f}\")\n",
    "\n",
    "print(f\"\\nСредний ARI между разбиениями: {np.mean(ari_scores):.4f}\")\n",
    "print(f\"Стандартное отклонение ARI: {np.std(ari_scores):.4f}\")\n",
    "\n",
    "# Статистика по метрикам\n",
    "stability_df = pd.DataFrame(stability_results)\n",
    "print(\"\\nСтатистика по метрикам:\")\n",
    "print(f\"Silhouette: среднее = {stability_df['silhouette'].mean():.4f}, std = {stability_df['silhouette'].std():.4f}\")\n",
    "print(f\"Davies-Bouldin: среднее = {stability_df['davies_bouldin'].mean():.4f}, std = {stability_df['davies_bouldin'].std():.4f}\")\n",
    "print(f\"Calinski-Harabasz: среднее = {stability_df['calinski_harabasz'].mean():.2f}, std = {stability_df['calinski_harabasz'].std():.2f}\")\n",
    "\n",
    "# Визуализация устойчивости\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].bar(stability_df['run'], stability_df['silhouette'], color='blue', alpha=0.7)\n",
    "axes[0].axhline(stability_df['silhouette'].mean(), color='red', linestyle='--', label='Среднее')\n",
    "axes[0].set_xlabel('Номер запуска')\n",
    "axes[0].set_ylabel('Silhouette Score')\n",
    "axes[0].set_title('Устойчивость: Silhouette Score')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].bar(stability_df['run'], stability_df['davies_bouldin'], color='red', alpha=0.7)\n",
    "axes[1].axhline(stability_df['davies_bouldin'].mean(), color='blue', linestyle='--', label='Среднее')\n",
    "axes[1].set_xlabel('Номер запуска')\n",
    "axes[1].set_ylabel('Davies-Bouldin Score')\n",
    "axes[1].set_title('Устойчивость: Davies-Bouldin Score')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].bar(stability_df['run'], stability_df['calinski_harabasz'], color='green', alpha=0.7)\n",
    "axes[2].axhline(stability_df['calinski_harabasz'].mean(), color='red', linestyle='--', label='Среднее')\n",
    "axes[2].set_xlabel('Номер запуска')\n",
    "axes[2].set_ylabel('Calinski-Harabasz Score')\n",
    "axes[2].set_title('Устойчивость: Calinski-Harabasz Score')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('artifacts/figures/ds03_stability_check.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Интерпретация\n",
    "if np.mean(ari_scores) > 0.9:\n",
    "    print(\"\\n✓ Кластеризация УСТОЙЧИВА: разбиения очень похожи (ARI > 0.9)\")\n",
    "elif np.mean(ari_scores) > 0.7:\n",
    "    print(\"\\n~ Кластеризация УМЕРЕННО УСТОЙЧИВА: разбиения достаточно похожи (0.7 < ARI < 0.9)\")\n",
    "else:\n",
    "    print(\"\\n✗ Кластеризация НЕУСТОЙЧИВА: разбиения сильно различаются (ARI < 0.7)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8. Итог по Dataset 03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоги по Dataset 03:**\n",
    "\n",
    "Dataset 03 представляет собой особенно сложный случай: кластеры разной плотности и фоновый шум. Это создает проблемы для всех алгоритмов кластеризации.\n",
    "\n",
    "**KMeans** предполагает, что все кластеры имеют примерно одинаковый размер и плотность, что не выполняется для этого датасета. Результат - кластеры могут быть разделены неоптимально.\n",
    "\n",
    "**DBSCAN** теоретически хорошо подходит для разной плотности, но требует единого параметра eps, что проблематично: малый eps выделит только плотные кластеры (разреженные попадут в шум), большой eps объединит все вместе.\n",
    "\n",
    "**Agglomerative Clustering** с правильным выбором linkage может справиться лучше:\n",
    "- `ward` - минимизирует внутрикластерную дисперсию, похож на KMeans\n",
    "- `complete` - основан на максимальном расстоянии, более чувствителен к выбросам\n",
    "- `average` - компромиссный вариант, часто более стабилен\n",
    "\n",
    "**Основные сложности:**\n",
    "- Разная плотность кластеров делает невозможным выбор единого порога плотности\n",
    "- Фоновый шум мешает определить границы кластеров\n",
    "- Необходим компромисс между выделением плотных кластеров и покрытием всех данных\n",
    "\n",
    "**Выбранный метод:** Для Dataset 03 был выбран метод с лучшими внутренними метриками. Agglomerative Clustering с подходящим linkage часто показывает хорошие результаты благодаря иерархической природе алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Сохранение артефактов эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание сводки метрик\n",
    "metrics_summary = {\n",
    "    \"dataset_01\": {\n",
    "        \"best_method\": \"KMeans\",\n",
    "        \"best_k\": int(best_k_1),\n",
    "        \"silhouette_score\": float(sil_1),\n",
    "        \"davies_bouldin_score\": float(db_1),\n",
    "        \"calinski_harabasz_score\": float(ch_1),\n",
    "        \"noise_percentage\": 0.0\n",
    "    },\n",
    "    \"dataset_02\": {\n",
    "        \"best_method\": best_method_2,\n",
    "        \"kmeans_silhouette\": float(sil_kmeans_2),\n",
    "        \"kmeans_davies_bouldin\": float(db_kmeans_2),\n",
    "        \"kmeans_calinski_harabasz\": float(ch_kmeans_2)\n",
    "    },\n",
    "    \"dataset_03\": {\n",
    "        \"best_method\": best_method_3,\n",
    "        \"kmeans_silhouette\": float(sil_kmeans_3),\n",
    "        \"kmeans_davies_bouldin\": float(db_kmeans_3),\n",
    "        \"kmeans_calinski_harabasz\": float(ch_kmeans_3),\n",
    "        \"agglomerative_silhouette\": float(best_agg_3['silhouette']),\n",
    "        \"agglomerative_davies_bouldin\": float(best_agg_3['davies_bouldin']),\n",
    "        \"agglomerative_calinski_harabasz\": float(best_agg_3['calinski_harabasz'])\n",
    "    }\n",
    "}\n",
    "\n",
    "# Добавляем информацию о DBSCAN для dataset_02 если есть\n",
    "if best_dbscan_2 is not None:\n",
    "    metrics_summary[\"dataset_02\"][\"dbscan_silhouette\"] = float(best_dbscan_2['silhouette'])\n",
    "    metrics_summary[\"dataset_02\"][\"dbscan_davies_bouldin\"] = float(best_dbscan_2['davies_bouldin'])\n",
    "    metrics_summary[\"dataset_02\"][\"dbscan_calinski_harabasz\"] = float(best_dbscan_2['calinski_harabasz'])\n",
    "    metrics_summary[\"dataset_02\"][\"dbscan_noise_percentage\"] = float(best_dbscan_2['noise_pct'])\n",
    "\n",
    "# Сохранение metrics_summary.json\n",
    "with open('artifacts/metrics_summary.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✓ Сохранен artifacts/metrics_summary.json\")\n",
    "\n",
    "# Создание best_configs.json\n",
    "best_configs = {\n",
    "    \"dataset_01\": {\n",
    "        \"method\": \"KMeans\",\n",
    "        \"parameters\": {\n",
    "            \"n_clusters\": int(best_k_1),\n",
    "            \"random_state\": 42,\n",
    "            \"n_init\": 10\n",
    "        },\n",
    "        \"selection_criterion\": \"max_silhouette_score\"\n",
    "    },\n",
    "    \"dataset_02\": {\n",
    "        \"method\": best_method_2,\n",
    "        \"parameters\": {} if best_method_2 == \"KMeans\" else {},\n",
    "        \"selection_criterion\": \"max_silhouette_score\"\n",
    "    },\n",
    "    \"dataset_03\": {\n",
    "        \"method\": best_method_3,\n",
    "        \"parameters\": {\n",
    "            \"n_clusters\": int(best_k_3) if best_method_3 == \"KMeans\" else int(best_agg_3['n_clusters']),\n",
    "            \"linkage\": best_agg_3['linkage'] if best_method_3 == \"Agglomerative\" else None\n",
    "        },\n",
    "        \"selection_criterion\": \"max_silhouette_score\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Добавляем параметры для dataset_02\n",
    "if best_method_2 == \"KMeans\":\n",
    "    best_configs[\"dataset_02\"][\"parameters\"] = {\n",
    "        \"n_clusters\": int(best_k_2),\n",
    "        \"random_state\": 42,\n",
    "        \"n_init\": 10\n",
    "    }\n",
    "elif best_dbscan_2 is not None:\n",
    "    best_configs[\"dataset_02\"][\"parameters\"] = {\n",
    "        \"eps\": float(best_dbscan_2['eps']),\n",
    "        \"min_samples\": int(best_dbscan_2['min_samples'])\n",
    "    }\n",
    "\n",
    "with open('artifacts/best_configs.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(best_configs, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✓ Сохранен artifacts/best_configs.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ВСЕ АРТЕФАКТЫ СОХРАНЕНЫ УСПЕШНО\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nСтруктура artifacts/:\")\n",
    "print(\"  - metrics_summary.json\")\n",
    "print(\"  - best_configs.json\")\n",
    "print(\"  - labels/\")\n",
    "print(\"      - labels_hw07_ds1.csv\")\n",
    "print(\"      - labels_hw07_ds2.csv\")\n",
    "print(\"      - labels_hw07_ds3.csv\")\n",
    "print(\"  - figures/\")\n",
    "print(\"      - ds01_kmeans_metrics_vs_k.png\")\n",
    "print(\"      - ds01_pca_best_solution.png\")\n",
    "print(\"      - ds02_kmeans_metrics_vs_k.png\")\n",
    "print(\"      - ds02_pca_best_solution.png\")\n",
    "print(\"      - ds02_comparison_kmeans_vs_dbscan.png (если DBSCAN применялся)\")\n",
    "print(\"      - ds03_kmeans_metrics_vs_k.png\")\n",
    "print(\"      - ds03_agglomerative_linkage_comparison.png\")\n",
    "print(\"      - ds03_pca_best_solution.png\")\n",
    "print(\"      - ds03_stability_check.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Общие выводы\n",
    "\n",
    "В данной работе были применены три семейства методов кластеризации (KMeans, DBSCAN, Agglomerative) к трем различным синтетическим датасетам. Каждый датасет представлял свои уникальные вызовы:\n",
    "\n",
    "**Dataset 01** показал важность масштабирования признаков для distance-based методов. KMeans хорошо справился с задачей при условии правильного выбора k.\n",
    "\n",
    "**Dataset 02** продемонстрировал ограничения KMeans при работе с нелинейными структурами и выбросами. DBSCAN показал свою способность обнаруживать кластеры произвольной формы.\n",
    "\n",
    "**Dataset 03** с кластерами разной плотности оказался наиболее сложным. Проверка устойчивости показала важность множественных запусков для оценки надежности результатов.\n",
    "\n",
    "**Ключевые уроки:**\n",
    "\n",
    "1. **Препроцессинг критичен:** StandardScaler обязателен для distance-based методов\n",
    "2. **Нет универсального алгоритма:** выбор метода зависит от структуры данных\n",
    "3. **Внутренние метрики помогают, но не заменяют анализ:** визуализация и интерпретация необходимы\n",
    "4. **Устойчивость важна:** проверка на разных random_state выявляет стабильность решения\n",
    "5. **PCA полезен для визуализации:** помогает понять структуру кластеров в 2D\n",
    "\n",
    "Работа выполнена в соответствии с требованиями HW07."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
