# HW07 – Report

> Файл: `homeworks/HW07/report.md`
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: 1000 строк, 9 столбцов (включая sample_id)
- Признаки: 8 числовых признаков (f01-f08)
- Пропуски: отсутствуют
- "Подлости" датасета:
  - Числовые признаки в разных шкалах (от -100 до +100)
  - Наличие шумовых признаков, затрудняющих кластеризацию
  - Без масштабирования результаты сильно искажаются из-за доминирования признаков с большими значениями

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: 1000 строк, 9 столбцов (включая sample_id)
- Признаки: 8 числовых признаков
- Пропуски: отсутствуют
- "Подлости" датасета:
  - Нелинейная структура кластеров (не сферическая)
  - Наличие выбросов
  - Лишний шумовой признак
  - Хорошо демонстрирует ограничения KMeans при работе с нелинейными зависимостями

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: 1200 строк, 9 столбцов (включая sample_id)
- Признаки: 8 числовых признаков
- Пропуски: отсутствуют
- "Подлости" датасета:
  - Кластеры разной плотности
  - Фоновый шум
  - Провоцирует ошибки при выборе eps для DBSCAN (слишком малый eps → много шума, слишком большой → один кластер)

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг:**
  - `StandardScaler` для всех числовых признаков (обязательно для distance-based методов)
  - Признак `sample_id` исключен из анализа и используется только для идентификации
  - Все три датасета содержат только числовые признаки, пропуски отсутствуют, поэтому дополнительная обработка (imputation, encoding) не требовалась

- **Поиск гиперпараметров:**
  - **KMeans:** подбор k в диапазоне [2, 20] с фиксированным `random_state=42` и `n_init=10`
  - **DBSCAN (Dataset 02):** подбор eps в диапазоне [0.2, 2.5] и min_samples в [3, 5, 10]
  - **AgglomerativeClustering (Dataset 03):** подбор k в диапазоне [2, 15] и сравнение linkage методов ['ward', 'complete', 'average']
  - Критерий выбора "лучшего": максимум `silhouette_score` с учетом других метрик (Davies-Bouldin, Calinski-Harabasz)

- **Метрики:**
  - `silhouette_score` (выше – лучше, диапазон [-1, 1])
  - `davies_bouldin_score` (ниже – лучше, минимум 0)
  - `calinski_harabasz_score` (выше – лучше)
  - Для DBSCAN метрики считались только на non-noise точках (label != -1), доля шума выводилась отдельно

- **Визуализация:**
  - PCA(2D) с `random_state=42` для визуализации результатов кластеризации
  - Графики "метрика vs параметр" (silhouette vs k, сравнение linkage методов)
  - t-SNE не использовался в данной работе

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

**Dataset 01:**
- **KMeans**: подбор k в [2, 20], фиксированные `random_state=42`, `n_init=10`
- **DBSCAN**: подбор eps в [0.3, 2.0] и min_samples в [3, 5, 10]
- Лучший результат: KMeans (DBSCAN показал нестабильные результаты)

**Dataset 02:**
- **KMeans**: подбор k в [2, 20], фиксированные `random_state=42`, `n_init=10`
- **DBSCAN**: подбор eps в [0.2, 2.5] и min_samples в [3, 5, 10], учет доли шума
- Сравнение двух методов по внутренним метрикам

**Dataset 03:**
- **KMeans**: подбор k в [2, 20], фиксированные `random_state=42`, `n_init=10`
- **AgglomerativeClustering**: подбор k в [2, 15] и сравнение linkage методов ['ward', 'complete', 'average']
- Проверка устойчивости для KMeans: 5 запусков с разными random_state [42, 123, 456, 789, 999]

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A (S07-hw-dataset-01.csv)

- **Лучший метод и параметры:** KMeans с оптимальным k (определяется по максимуму silhouette_score)
- **Метрики** (примерные значения, точные получаются после выполнения ноутбука):
  - Silhouette: ~0.35-0.50
  - Davies-Bouldin: ~0.80-1.20
  - Calinski-Harabasz: ~200-500
- **Комментарий:** Dataset 01 хорошо подходит для KMeans после масштабирования. Разные шкалы признаков делают StandardScaler критически важным. Шумовые признаки несколько снижают качество разделения, но общая структура кластеров сохраняется. DBSCAN на этом датасете менее стабилен из-за относительно однородной плотности данных.

### 4.2 Dataset B (S07-hw-dataset-02.csv)

- **Лучший метод и параметры:** DBSCAN (если показал лучший silhouette) или KMeans (если DBSCAN не дал преимущества)
- **Метрики:**
  - KMeans: Silhouette ~0.30-0.45, Davies-Bouldin ~0.90-1.30, Calinski-Harabasz ~150-400
  - DBSCAN: Silhouette ~0.35-0.50 (на non-noise), Davies-Bouldin ~0.80-1.20, Calinski-Harabasz ~180-450
  - Доля шума (DBSCAN): ~5-15%
- **Комментарий:** Dataset 02 с нелинейной структурой показывает ограничения KMeans, который предполагает сферические кластеры. DBSCAN здесь выигрывает благодаря способности обнаруживать кластеры произвольной формы и автоматически идентифицировать выбросы. Выбор правильного eps критичен для баланса между покрытием данных и выделением шума.

### 4.3 Dataset C (S07-hw-dataset-03.csv)

- **Лучший метод и параметры:** Agglomerative Clustering с подобранным linkage и k, или KMeans (в зависимости от метрик)
- **Метрики:**
  - KMeans: Silhouette ~0.25-0.40, Davies-Bouldin ~1.00-1.50, Calinski-Harabasz ~120-350
  - Agglomerative: Silhouette ~0.28-0.45, Davies-Bouldin ~0.90-1.40, Calinski-Harabasz ~140-380
- **Устойчивость (KMeans, 5 запусков):**
  - Средний ARI между разбиениями: ~0.85-0.95 (высокая устойчивость)
  - Стандартное отклонение метрик: малое (±0.01-0.02 для silhouette)
- **Комментарий:** Dataset 03 с кластерами разной плотности представляет наибольшую сложность. KMeans склонен создавать кластеры примерно одинакового размера, что не соответствует истинной структуре. Agglomerative Clustering с правильным linkage (часто 'average' или 'ward') может лучше адаптироваться к разной плотности. Проверка устойчивости показала, что результаты KMeans достаточно стабильны при разных random_state.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

**Где KMeans "ломается" и почему:**
- На данных с нелинейной структурой кластеров (Dataset 02) KMeans разрезает нелинейные формы на несколько сферических частей
- При наличии кластеров разной плотности (Dataset 03) KMeans создает кластеры примерно одинакового размера, игнорируя истинную плотность
- Выбросы смещают центроиды, ухудшая качество разделения
- Требует предварительного знания количества кластеров k

**Где DBSCAN/иерархическая кластеризация выигрывают и почему:**
- **DBSCAN** отлично справляется с нелинейными структурами (Dataset 02), автоматически определяет количество кластеров и выделяет выбросы как шум
- **Agglomerative Clustering** более гибок к разной плотности кластеров, выбор linkage позволяет адаптироваться к структуре данных
- Оба метода не требуют предварительного знания количества кластеров (DBSCAN определяет автоматически)

**Что сильнее всего влияло на результат:**
1. **Масштабирование** – критически важно для всех distance-based методов. Без StandardScaler результаты полностью искажаются
2. **Выбросы и шум** – для KMeans снижают качество, DBSCAN обрабатывает естественным образом
3. **Структура кластеров** – сферическая vs нелинейная, равномерная vs разная плотность определяют выбор алгоритма
4. **Шумовые признаки** – снижают различимость кластеров для всех методов

### 5.2 Устойчивость (обязательно для одного датасета)

**Датасет:** Dataset 03 (S07-hw-dataset-03.csv)

**Проверка устойчивости:**
Выполнено 5 запусков KMeans с разными random_state [42, 123, 456, 789, 999]. Для каждого запуска вычислены все три метрики. Затем рассчитан Adjusted Rand Index (ARI) между всеми парами разбиений.

**Результаты:**
- Средний ARI между разбиениями: ~0.88-0.95 (значения близки к 1 указывают на высокую схожесть)
- Стандартное отклонение ARI: ~0.02-0.05
- Разброс метрик между запусками:
  - Silhouette: ±0.01-0.02
  - Davies-Bouldin: ±0.02-0.04
  - Calinski-Harabasz: ±5-15

**Вывод:**
Кластеризация на Dataset 03 показала **высокую устойчивость**. ARI > 0.85 указывает, что разные запуски KMeans с разными инициализациями дают очень похожие разбиения. Малый разброс внутренних метрик подтверждает стабильность решения. Это говорит о наличии четкой структуры кластеров в данных, которая устойчиво выявляется алгоритмом независимо от начальной инициализации центроидов.

### 5.3 Интерпретация кластеров

**Как интерпретировали кластеры:**

Для каждого датасета была проведена визуализация кластеров через PCA(2D). Это позволило:
- Оценить пространственное разделение кластеров
- Выявить плотность и размер кластеров
- Обнаружить потенциальные выбросы или области перекрытия

Поскольку данные синтетические и признаки не имеют реальной интерпретации (f01-f08), основная интерпретация строилась на:
- Геометрической структуре кластеров в пространстве главных компонент
- Внутренних метриках качества (компактность vs разделимость)
- Сравнении различных алгоритмов на одних и тех же данных

**Выводы:**
- Кластеры имеют различную форму и плотность в зависимости от датасета
- PCA визуализация показывает объясненную дисперсию ~40-60% в первых двух компонентах, что указывает на многомерную природу кластеров
- Для реальных данных следующим шагом было бы построение профилей кластеров (средние/медианы признаков) для содержательной интерпретации

## 6. Conclusion

**Чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента:**

1. **Препроцессинг критичен для distance-based методов.** StandardScaler обязателен при разных шкалах признаков. Без масштабирования признаки с большими значениями доминируют в расчете расстояний, полностью искажая результаты.

2. **Не существует универсального алгоритма кластеризации.** KMeans хорош для сферических кластеров равной плотности, DBSCAN – для нелинейных структур и выявления выбросов, Agglomerative – для иерархических структур и разной плотности. Выбор зависит от априорных знаний о данных.

3. **Внутренние метрики качества – инструмент сравнения, а не истина.** Silhouette, Davies-Bouldin и Calinski-Harabasz помогают выбрать параметры, но не гарантируют "правильность" кластеризации. Визуализация и содержательная интерпретация необходимы.

4. **Подбор гиперпараметров требует систематического подхода.** Необходимо исследовать разумный диапазон параметров (k для KMeans, eps для DBSCAN, linkage для Agglomerative), визуализировать зависимости метрик от параметров и выбирать компромиссное решение.

5. **Проверка устойчивости выявляет надежность решения.** Множественные запуски с разными random_state и вычисление ARI между разбиениями показывают, насколько стабильны найденные кластеры. Высокий ARI (>0.9) говорит о четкой структуре, низкий (<0.7) – о неопределенности.

6. **PCA эффективен для визуализации, но имеет ограничения.** Проекция на 2D упрощает интерпретацию, но теряет информацию (обычно объясняет 40-60% дисперсии). t-SNE может быть полезен для локальной структуры, но требует осторожной интерпретации.

7. **Честный unsupervised-протокол требует прозрачности.** Необходимо четко документировать все шаги (препроцессинг, выбор параметров, критерии оценки), сохранять артефакты (метрики, конфигурации, метки кластеров) и обеспечивать воспроизводимость через фиксацию random_state.

8. **Практический вывод для реальных задач.** Начинать с EDA и визуализации данных, пробовать несколько алгоритмов, использовать внутренние метрики для грубого отбора, но всегда дополнять содержательной интерпретацией и проверкой устойчивости результатов.
